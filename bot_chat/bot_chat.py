# save as app.py
import streamlit as st
import json
import re
from difflib import SequenceMatcher
import random

# Configure page
st.set_page_config(
    page_title="COVID-19 Healthcare Assistant",
    page_icon="ü¶†",
    layout="wide"
)


# Load knowledge base
@st.cache_data
def load_knowledge_base():
    try:
        # Load all knowledge bases
        knowledge_bases = {}
        
        # Load COVID-19 knowledge base
        with open('data/covid.json', 'r', encoding='utf-8') as f:
            covid_kb = json.load(f)
            knowledge_bases["covid19"] = covid_kb["covid19_knowledge_base"]
            
        # Load Cold knowledge base
        with open('data/cold.json', 'r', encoding='utf-8') as f:
            cold_kb = json.load(f)
            knowledge_bases["cold"] = cold_kb
            
        # Load Allergy knowledge base
        with open('data/allergy.json', 'r', encoding='utf-8') as f:
            allergy_kb = json.load(f)
            knowledge_bases["allergy"] = allergy_kb
            
        # Load Flu knowledge base
        with open('data/flu.json', 'r', encoding='utf-8') as f:
            flu_kb = json.load(f)
            knowledge_bases["flu"] = flu_kb
            
        return knowledge_bases
    except FileNotFoundError as e:
        st.error(f"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y file knowledge base: {str(e)}")
        return None
    except json.JSONDecodeError:
        st.error("‚ö†Ô∏è L·ªói ƒë·ªçc file JSON. Vui l√≤ng ki·ªÉm tra c√∫ ph√°p file.")
        return None


# Load ontology data
@st.cache_data
def load_ontology_data():
    try:
        ontologies = {}
        
        # Load COVID-19 ontology
        with open('data/ontology/covid_ontology.json', 'r', encoding='utf-8') as f:
            covid_onto = json.load(f)
            ontologies["covid19"] = covid_onto
            
        # Load Cold ontology
        with open('data/ontology/cold_ontology.json', 'r', encoding='utf-8') as f:
            cold_onto = json.load(f)
            ontologies["cold"] = cold_onto
            
        # Load Allergy ontology
        with open('data/ontology/allergy_ontology.json', 'r', encoding='utf-8') as f:
            allergy_onto = json.load(f)
            ontologies["allergy"] = allergy_onto
            
        # Load Flu ontology
        with open('data/ontology/flu_ontology.json', 'r', encoding='utf-8') as f:
            flu_onto = json.load(f)
            ontologies["flu"] = flu_onto
            
        return ontologies
    except FileNotFoundError as e:
        st.error(f"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y file ontology: {str(e)}")
        return None
    except json.JSONDecodeError:
        st.error("‚ö†Ô∏è L·ªói ƒë·ªçc file ontology JSON. Vui l√≤ng ki·ªÉm tra c√∫ ph√°p file.")
        return None


# Similarity function for fuzzy matching
def similarity(a, b):
    return SequenceMatcher(None, a.lower(), b.lower()).ratio()


# Ph√¢n t√≠ch √Ω ƒë·ªãnh ng∆∞·ªùi d√πng
def analyze_user_intent(user_input):
    """Ph√¢n t√≠ch √Ω ƒë·ªãnh c·ªßa ng∆∞·ªùi d√πng t·ª´ c√¢u h·ªèi"""
    user_input_lower = user_input.lower().strip()
    
    # X·ª≠ l√Ω c√°c intent c∆° b·∫£n (social intents)
    social_intent_patterns = {
        "greeting": ["xin ch√†o", "ch√†o", "hello", "hi", "hey", "good morning", "good afternoon", 
                    "good evening", "ch√†o b·∫°n", "xin ch√†o b·∫°n", "ch√†o bot"],
        "goodbye": ["t·∫°m bi·ªát", "bye", "goodbye", "see you", "h·∫πn g·∫∑p l·∫°i", "ch√†o t·∫°m bi·ªát", 
                   "k·∫øt th√∫c", "tho√°t", "quit", "exit"],
        "thanks": ["c·∫£m ∆°n", "thank you", "thanks", "c·∫£m ∆°n b·∫°n", "c·∫£m ∆°n bot", "thanks bot"],
        "how_are_you": ["b·∫°n kh·ªèe kh√¥ng", "how are you", "b·∫°n th·∫ø n√†o", "t√¨nh h√¨nh nh∆∞ th·∫ø n√†o"],
        "what_can_you_do": ["b·∫°n c√≥ th·ªÉ l√†m g√¨", "what can you do", "b·∫°n h·ªó tr·ª£ g√¨", 
                           "t√¥i c√≥ th·ªÉ h·ªèi g√¨", "b·∫°n bi·∫øt g√¨", "gi√∫p t√¥i g√¨ ƒë∆∞·ª£c"],
        "ask_more": ["c√≥ g√¨ kh√°c kh√¥ng", "t√¥i mu·ªën h·ªèi th√™m", "c√≤n g√¨ n·ªØa", "h·ªèi th√™m", 
                    "anything else", "what else", "c√≤n g√¨ kh√°c"],
        "compliment": ["b·∫°n gi·ªèi qu√°", "tuy·ªát v·ªùi", "great", "good job", "excellent", "hay qu√°"],
        "help": ["help", "gi√∫p ƒë·ª°", "h∆∞·ªõng d·∫´n", "tr·ª£ gi√∫p", "h·ªó tr·ª£"]
    }
    
    # Ki·ªÉm tra social intents tr∆∞·ªõc
    for intent, patterns in social_intent_patterns.items():
        for pattern in patterns:
            if pattern in user_input_lower:
                return intent
    
    # Ki·ªÉm tra n·∫øu ng∆∞·ªùi d√πng m√¥ t·∫£ tri·ªáu ch·ª©ng tr·ª±c ti·∫øp
    personal_symptoms_patterns = ["t√¥i b·ªã", "em b·ªã", "m√¨nh b·ªã", "b·ªã", "c√≥ tri·ªáu ch·ª©ng", 
                                 "ƒëang b·ªã", "c·∫£m th·∫•y", "th·∫•y", "i have", "i feel"]
    
    for pattern in personal_symptoms_patterns:
        if pattern in user_input_lower:
            # Ki·ªÉm tra xem c√≥ tri·ªáu ch·ª©ng n√†o ƒë∆∞·ª£c ƒë·ªÅ c·∫≠p kh√¥ng
            symptoms = extract_symptoms_from_input(user_input)
            if symptoms:
                return "symptom_analysis"
    
    # Intent patterns cho y t·∫ø
    medical_intent_patterns = {
        "treatment": ["n√™n l√†m g√¨", "ƒëi·ªÅu tr·ªã", "ch·ªØa", "x·ª≠ l√Ω", "u·ªëng thu·ªëc g√¨", "l√†m sao ƒë·ªÉ", 
                     "c√°ch ch·ªØa", "c√°ch ƒëi·ªÅu tr·ªã", "c·∫ßn l√†m g√¨", "ch·ªØa tr·ªã"],
        "prevention": ["ph√≤ng ng·ª´a", "tr√°nh", "ngƒÉn ng·ª´a", "c√°ch ph√≤ng", "b·∫£o v·ªá"],
        "symptoms": ["tri·ªáu ch·ª©ng", "d·∫•u hi·ªáu", "bi·ªÉu hi·ªán", "c√≥ tri·ªáu ch·ª©ng g√¨"],
        "definition": ["l√† g√¨", "ƒë·ªãnh nghƒ©a", "th√¥ng tin", "t√¨m hi·ªÉu v·ªÅ"],
        "vaccine": ["v·∫Øc xin", "ti√™m ch·ªßng", "vaccine"],
        "emergency": ["c·∫•p c·ª©u", "kh·∫©n c·∫•p", "nguy hi·ªÉm", "nghi√™m tr·ªçng"]
    }
    
    detected_intents = []
    for intent, patterns in medical_intent_patterns.items():
        for pattern in patterns:
            if pattern in user_input_lower:
                detected_intents.append(intent)
                break
    
    # ∆Øu ti√™n intent
    priority_order = ["emergency", "symptom_analysis", "treatment", "symptoms", "prevention", "vaccine", "definition"]
    
    for intent in priority_order:
        if intent in detected_intents:
            return intent
    
    return "general"


def extract_symptoms_from_input(user_input):
    """Tr√≠ch xu·∫•t tri·ªáu ch·ª©ng t·ª´ ng√¥n ng·ªØ t·ª± nhi√™n"""
    user_input_lower = user_input.lower()
    
    # Dictionary mapping tri·ªáu ch·ª©ng v·ªõi c√°c t·ª´ kh√≥a
    symptom_keywords = {
        "ho": ["ho", "ho khan", "ho c√≥ ƒë·ªùm", "kh·∫°c ƒë·ªùm", "coughing"],
        "s·ªët": ["s·ªët", "n√≥ng ng∆∞·ªùi", "·ªõn l·∫°nh", "fever", "b·ªã s·ªët", "s·ªët cao"],
        "ƒëau h·ªçng": ["ƒëau h·ªçng", "r√°t h·ªçng", "kh√≥ nu·ªët", "sore throat", "h·ªçng ƒëau"],
        "kh√≥ th·ªü": ["kh√≥ th·ªü", "th·ªü kh√≥", "ng·∫°t th·ªü", "th·ªü g·∫•p", "difficulty breathing"],
        "m·ªát m·ªèi": ["m·ªát", "m·ªát m·ªèi", "ki·ªát s·ª©c", "u·ªÉ o·∫£i", "fatigue", "tired"],
        "ƒëau ƒë·∫ßu": ["ƒëau ƒë·∫ßu", "nh·ª©c ƒë·∫ßu", "headache", "ƒë·∫ßu ƒëau"],
        "s·ªï m≈©i": ["s·ªï m≈©i", "ch·∫£y n∆∞·ªõc m≈©i", "runny nose", "m≈©i ch·∫£y"],
        "ngh·∫πt m≈©i": ["ngh·∫πt m≈©i", "t·∫Øc m≈©i", "blocked nose", "m≈©i b·ªã t·∫Øc"],
        "m·∫•t v·ªã gi√°c": ["m·∫•t v·ªã", "kh√¥ng c·∫£m nh·∫≠n v·ªã", "loss of taste", "m·∫•t v·ªã gi√°c"],
        "m·∫•t kh·ª©u gi√°c": ["m·∫•t m√πi", "kh√¥ng ng·ª≠i ƒë∆∞·ª£c", "loss of smell", "m·∫•t kh·ª©u gi√°c"],
        "bu·ªìn n√¥n": ["bu·ªìn n√¥n", "n√¥n", "nausea", "mu·ªën n√¥n"],
        "ti√™u ch·∫£y": ["ti√™u ch·∫£y", "ƒëi l·ªèng", "diarrhea", "b·ª•ng xo·∫Øn"],
        "ƒëau c∆°": ["ƒëau c∆°", "nh·ª©c c∆°", "muscle pain", "c∆° th·ªÉ ƒëau"],
        "ng·ª©a": ["ng·ª©a", "ng·ª©a ng√°y", "itchy", "swelling"],
        "ph√°t ban": ["ph√°t ban", "n·ªïi m·ªÅ ƒëay", "rash", "ban ƒë·ªè", "m·∫©n ƒë·ªè"],
        "h·∫Øt h∆°i": ["h·∫Øt h∆°i", "sneezing", "hay h·∫Øt h∆°i"]
    }
    
    detected_symptoms = []
    for symptom, keywords in symptom_keywords.items():
        for keyword in keywords:
            if keyword in user_input_lower:
                detected_symptoms.append(symptom)
                break
    
    return detected_symptoms


def analyze_symptoms_to_diseases(symptoms):
    """Ph√¢n t√≠ch tri·ªáu ch·ª©ng ƒë·ªÉ ƒë∆∞a ra c√°c b·ªánh c√≥ th·ªÉ"""
    if not symptoms:
        return []
    
    # Mapping tri·ªáu ch·ª©ng v·ªõi c√°c b·ªánh v√† probability
    disease_symptom_mapping = {
        "covid19": {
            "common": ["s·ªët", "ho", "m·ªát m·ªèi", "ƒëau h·ªçng", "m·∫•t v·ªã gi√°c", "m·∫•t kh·ª©u gi√°c"],
            "moderate": ["kh√≥ th·ªü", "ƒëau ƒë·∫ßu", "ƒëau c∆°"],
            "severe": ["kh√≥ th·ªü", "ƒëau ng·ª±c"]
        },
        "flu": {
            "common": ["s·ªët", "ho", "ƒëau ƒë·∫ßu", "m·ªát m·ªèi", "ƒëau c∆°"],
            "moderate": ["ƒëau h·ªçng", "bu·ªìn n√¥n"],
            "severe": ["kh√≥ th·ªü"]
        },
        "cold": {
            "common": ["s·ªï m≈©i", "ngh·∫πt m≈©i", "ƒëau h·ªçng", "ho"],
            "moderate": ["ƒëau ƒë·∫ßu", "m·ªát m·ªèi"],
            "severe": []
        },
        "allergy": {
            "common": ["h·∫Øt h∆°i", "ng·ª©a", "s·ªï m≈©i", "ph√°t ban"],
            "moderate": ["ngh·∫πt m≈©i", "kh√≥ th·ªü"],
            "severe": ["kh√≥ th·ªü"]
        }
    }
    
    disease_scores = {}
    
    for disease, symptom_groups in disease_symptom_mapping.items():
        score = 0
        matched_symptoms = []
        
        for symptom in symptoms:
            if symptom in symptom_groups["common"]:
                score += 3
                matched_symptoms.append(symptom)
            elif symptom in symptom_groups["moderate"]:
                score += 2
                matched_symptoms.append(symptom)
            elif symptom in symptom_groups["severe"]:
                score += 4
                matched_symptoms.append(symptom)
        
        if score > 0:
            disease_scores[disease] = {
                "score": score,
                "matched_symptoms": matched_symptoms,
                "confidence": min(score / 10.0, 0.95)  # Normalize to 0-0.95
            }
    
    # S·∫Øp x·∫øp theo ƒëi·ªÉm s·ªë
    sorted_diseases = sorted(disease_scores.items(), key=lambda x: x[1]["score"], reverse=True)
    return sorted_diseases


def detect_disease_from_input(user_input):
    """Ph√°t hi·ªán b·ªánh t·ª´ input ng∆∞·ªùi d√πng"""
    user_input_lower = user_input.lower()
    
    disease_keywords = {
        "covid19": ["covid", "covid-19", "corona", "coronavirus", "sars-cov-2"],
        "cold": ["c·∫£m l·∫°nh", "c·∫£m c√∫m", "l·∫°nh", "common cold"],
        "flu": ["c√∫m", "flu", "influenza", "c√∫m m√πa"],
        "allergy": ["d·ªã ·ª©ng", "allergy", "allergic", "ph·∫£n ·ª©ng d·ªã ·ª©ng"]
    }
    
    for disease, keywords in disease_keywords.items():
        for keyword in keywords:
            if keyword in user_input_lower:
                return disease
    
    return None


# Ontology-based information extraction v·ªõi intent awareness
def extract_from_ontology(disease_type, user_input, ontology_data):
    """Tr√≠ch xu·∫•t th√¥ng tin t·ª´ ontology d·ª±a tr√™n lo·∫°i b·ªánh v√† intent ng∆∞·ªùi d√πng"""
    if not ontology_data or disease_type not in ontology_data:
        return None, 0
    
    ontology = ontology_data[disease_type]
    user_intent = analyze_user_intent(user_input)
    best_answer = None
    best_score = 0
    
    # T√¨m ki·∫øm trong qa_pairs c·ªßa ontology v·ªõi ∆∞u ti√™n theo intent
    if "qa_pairs" in ontology and "categories" in ontology["qa_pairs"]:
        for category_key, category in ontology["qa_pairs"]["categories"].items():
            if "data" in category:
                for item in category["data"]:
                    # T√≠nh ƒëi·ªÉm d·ª±a tr√™n intent matching
                    intent_bonus = 0
                    question = item.get("question", "").lower()
                    
                    # √Åp d·ª•ng bonus ƒëi·ªÉm theo intent
                    if user_intent == "treatment" and any(word in question for word in ["ƒëi·ªÅu tr·ªã", "ch·ªØa", "l√†m g√¨", "x·ª≠ l√Ω"]):
                        intent_bonus = 0.3
                    elif user_intent == "prevention" and any(word in question for word in ["ph√≤ng ng·ª´a", "tr√°nh", "b·∫£o v·ªá"]):
                        intent_bonus = 0.3
                    elif user_intent == "symptoms" and any(word in question for word in ["tri·ªáu ch·ª©ng", "d·∫•u hi·ªáu"]):
                        intent_bonus = 0.3
                    elif user_intent == "definition" and any(word in question for word in ["l√† g√¨", "th√¥ng tin"]):
                        intent_bonus = 0.2
                    elif user_intent == "vaccine" and any(word in question for word in ["v·∫Øc xin", "ti√™m"]):
                        intent_bonus = 0.3
                    
                    # Ki·ªÉm tra similarity v·ªõi question
                    question_score = similarity(user_input, item.get("question", "")) + intent_bonus
                    if question_score > best_score:
                        best_score = question_score
                        best_answer = item
                    
                    # Ki·ªÉm tra keywords v·ªõi intent bonus
                    keywords = item.get("keywords", [])
                    for keyword in keywords:
                        if keyword.lower() in user_input.lower():
                            keyword_score = (similarity(user_input, keyword) * 0.9) + intent_bonus
                            if keyword_score > best_score:
                                best_score = keyword_score
                                best_answer = item
    
    return best_answer, best_score


def get_ontology_symptom_analysis(disease_type, symptoms, ontology_data):
    """Ph√¢n t√≠ch tri·ªáu ch·ª©ng d·ª±a tr√™n ontology"""
    if not ontology_data or disease_type not in ontology_data:
        return {}
    
    ontology = ontology_data[disease_type]
    analysis = {}
    
    # Tr√≠ch xu·∫•t th√¥ng tin tri·ªáu ch·ª©ng t·ª´ ontology instances
    if "ontology" in ontology and "instances" in ontology["ontology"]:
        instances = ontology["ontology"]["instances"]
        
        if "symptoms" in instances:
            ontology_symptoms = instances["symptoms"]
            matched_symptoms = []
            
            for symptom in symptoms:
                for onto_symptom in ontology_symptoms:
                    symptom_name = onto_symptom.get("name", "")
                    if symptom.lower() in symptom_name.lower() or symptom_name.lower() in symptom.lower():
                        matched_symptoms.append({
                            "name": symptom_name,
                            "severity": onto_symptom.get("severity", "Unknown"),
                            "duration": onto_symptom.get("duration", "Unknown"),
                            "description": onto_symptom.get("description", "")
                        })
            
            analysis["matched_symptoms"] = matched_symptoms
        
        # Tr√≠ch xu·∫•t th√¥ng tin ƒëi·ªÅu tr·ªã
        if "treatments" in instances:
            relevant_treatments = []
            for treatment in instances["treatments"]:
                relevant_treatments.append({
                    "name": treatment.get("name", ""),
                    "type": treatment.get("type", ""),
                    "effectiveness": treatment.get("effectiveness", ""),
                    "description": treatment.get("description", "")
                })
            analysis["treatments"] = relevant_treatments
        
        # Tr√≠ch xu·∫•t th√¥ng tin ph√≤ng ng·ª´a
        if "preventions" in instances:
            prevention_measures = []
            for prevention in instances["preventions"]:
                prevention_measures.append({
                    "name": prevention.get("name", ""),
                    "type": prevention.get("type", ""),
                    "effectiveness": prevention.get("effectiveness", ""),
                    "description": prevention.get("description", "")
                })
            analysis["preventions"] = prevention_measures
    
    return analysis


def get_emergency_response(disease_type, ontology_data):
    """L·∫•y th√¥ng tin c·∫•p c·ª©u t·ª´ ontology"""
    if not ontology_data or disease_type not in ontology_data:
        return None
    
    ontology = ontology_data[disease_type]
    
    if "chatbot_responses" in ontology and "emergency" in ontology["chatbot_responses"]:
        return ontology["chatbot_responses"]["emergency"][0]
    
    return None


def create_social_response(intent, user_input=""):
    """T·∫°o c√¢u tr·∫£ l·ªùi cho c√°c intent x√£ giao c∆° b·∫£n"""
    
    social_responses = {
        "greeting": [
            "Xin ch√†o! üëã T√¥i l√† tr·ª£ l√Ω s·ª©c kh·ªèe AI. T√¥i c√≥ th·ªÉ gi√∫p b·∫°n t√¨m hi·ªÉu v·ªÅ COVID-19, c·∫£m l·∫°nh, c√∫m, d·ªã ·ª©ng v√† c√°c v·∫•n ƒë·ªÅ s·ª©c kh·ªèe kh√°c. B·∫°n c·∫ßn h·ªó tr·ª£ g√¨ h√¥m nay?",
            "Ch√†o b·∫°n! üòä R·∫•t vui ƒë∆∞·ª£c h·ªó tr·ª£ b·∫°n v·ªÅ c√°c v·∫•n ƒë·ªÅ s·ª©c kh·ªèe. B·∫°n c√≥ tri·ªáu ch·ª©ng n√†o c·∫ßn t∆∞ v·∫•n ho·∫∑c mu·ªën t√¨m hi·ªÉu v·ªÅ b·ªánh n√†o kh√¥ng?",
            "Xin ch√†o! üè• T√¥i s·∫µn s√†ng t∆∞ v·∫•n cho b·∫°n v·ªÅ s·ª©c kh·ªèe. H√£y chia s·∫ª tri·ªáu ch·ª©ng ho·∫∑c c√¢u h·ªèi c·ªßa b·∫°n nh√©!"
        ],
        
        "goodbye": [
            "T·∫°m bi·ªát! üëã Ch√∫c b·∫°n lu√¥n kh·ªèe m·∫°nh. Nh·ªõ ƒëi kh√°m b√°c sƒ© n·∫øu c√≥ tri·ªáu ch·ª©ng b·∫•t th∆∞·ªùng nh√©!",
            "Ch√†o t·∫°m bi·ªát! üòä Hy v·ªçng th√¥ng tin t√¥i cung c·∫•p h·ªØu √≠ch cho b·∫°n. H√£y chƒÉm s√≥c s·ª©c kh·ªèe th·∫≠t t·ªët!",
            "T·∫°m bi·ªát v√† ch√∫c b·∫°n s·ª©c kh·ªèe! üåü H√£y quay l·∫°i n·∫øu c√≥ th√™m c√¢u h·ªèi v·ªÅ s·ª©c kh·ªèe."
        ],
        
        "thanks": [
            "R·∫•t vui ƒë∆∞·ª£c gi√∫p ƒë·ª° b·∫°n! üòä N·∫øu c√≥ th√™m c√¢u h·ªèi v·ªÅ s·ª©c kh·ªèe, ƒë·ª´ng ng·∫ßn ng·∫°i h·ªèi t√¥i nh√©!",
            "Kh√¥ng c√≥ g√¨! ü§ó S·ª©c kh·ªèe l√† ƒëi·ªÅu quan tr·ªçng nh·∫•t. T√¥i lu√¥n s·∫µn s√†ng h·ªó tr·ª£ b·∫°n.",
            "C·∫£m ∆°n b·∫°n! üíö Hy v·ªçng th√¥ng tin ƒë√£ gi√∫p √≠ch cho b·∫°n. Ch√∫c b·∫°n s·ª©c kh·ªèe!"
        ],
        
        "how_are_you": [
            "T√¥i ƒëang ho·∫°t ƒë·ªông t·ªët v√† s·∫µn s√†ng h·ªó tr·ª£ b·∫°n! ü§ñüí™ C√≤n b·∫°n th√¨ sao? C√≥ v·∫•n ƒë·ªÅ g√¨ v·ªÅ s·ª©c kh·ªèe c·∫ßn t∆∞ v·∫•n kh√¥ng?",
            "T√¥i kh·ªèe v√† lu√¥n s·∫µn s√†ng gi√∫p ƒë·ª°! üòä B·∫°n c√≥ c·∫£m th·∫•y kh·ªèe m·∫°nh kh√¥ng? C√≥ tri·ªáu ch·ª©ng n√†o c·∫ßn quan t√¢m kh√¥ng?",
            "C·∫£m ∆°n b·∫°n h·ªèi thƒÉm! T√¥i ho·∫°t ƒë·ªông b√¨nh th∆∞·ªùng. üåü Quan tr·ªçng h∆°n l√† s·ª©c kh·ªèe c·ªßa b·∫°n - b·∫°n c√≥ ·ªïn kh√¥ng?"
        ],
        
        "what_can_you_do": [
            "T√¥i c√≥ th·ªÉ gi√∫p b·∫°n:\n\nüîç **Ph√¢n t√≠ch tri·ªáu ch·ª©ng** - B·∫°n m√¥ t·∫£ tri·ªáu ch·ª©ng, t√¥i s·∫Ω ƒë∆∞a ra c√°c b·ªánh c√≥ th·ªÉ\nüíä **T∆∞ v·∫•n ƒëi·ªÅu tr·ªã** - C√°ch x·ª≠ l√Ω khi m·∫Øc b·ªánh\nüõ°Ô∏è **H∆∞·ªõng d·∫´n ph√≤ng ng·ª´a** - C√°ch b·∫£o v·ªá s·ª©c kh·ªèe\nüìã **Th√¥ng tin b·ªánh** - Gi·∫£i th√≠ch v·ªÅ COVID-19, c√∫m, c·∫£m l·∫°nh, d·ªã ·ª©ng\nüö® **C·∫£nh b√°o kh·∫©n c·∫•p** - Nh·∫≠n bi·∫øt khi c·∫ßn ƒëi b√°c sƒ© ngay\n\nH√£y th·ª≠ n√≥i 'T√¥i b·ªã ho v√† s·ªët' ho·∫∑c h·ªèi 'C√°ch ph√≤ng ng·ª´a COVID-19'!",
            "T√¥i chuy√™n h·ªó tr·ª£ v·ªÅ s·ª©c kh·ªèe! üè•\n\n‚ú® **Ch·ª©c nƒÉng ch√≠nh:**\n- Ph√¢n t√≠ch tri·ªáu ch·ª©ng th√¥ng minh\n- T∆∞ v·∫•n ƒëi·ªÅu tr·ªã c∆° b·∫£n\n- H∆∞·ªõng d·∫´n ph√≤ng ng·ª´a b·ªánh\n- Th√¥ng tin v·ªÅ COVID-19, c√∫m, c·∫£m l·∫°nh, d·ªã ·ª©ng\n- C·∫£nh b√°o t√¨nh hu·ªëng kh·∫©n c·∫•p\n\nV√≠ d·ª•: H√£y th·ª≠ h·ªèi 'Tri·ªáu ch·ª©ng COVID-19' ho·∫∑c 'T√¥i b·ªã ƒëau h·ªçng'!"
        ],
        
        "ask_more": [
            "T·∫•t nhi√™n! T√¥i lu√¥n s·∫µn s√†ng tr·∫£ l·ªùi th√™m c√¢u h·ªèi. üòä\n\nü§î B·∫°n c√≥ th·ªÉ h·ªèi v·ªÅ:\n- Tri·ªáu ch·ª©ng b·∫°n ƒëang g·∫∑p ph·∫£i\n- C√°ch ƒëi·ªÅu tr·ªã c√°c b·ªánh th∆∞·ªùng g·∫∑p\n- Bi·ªán ph√°p ph√≤ng ng·ª´a\n- Th√¥ng tin v·ªÅ v·∫Øc xin\n- Khi n√†o c·∫ßn ƒëi kh√°m b√°c sƒ©\n\nB·∫°n mu·ªën h·ªèi g√¨ ti·∫øp theo?",
            "Dƒ© nhi√™n r·ªìi! üåü S·ª©c kh·ªèe l√† ch·ªß ƒë·ªÅ r·ªông l·ªõn, t√¥i c√≥ th·ªÉ gi√∫p b·∫°n nhi·ªÅu vi·ªác:\n\nüí≠ **G·ª£i √Ω c√¢u h·ªèi:**\n- 'C√°ch ph√¢n bi·ªát c√∫m v√† c·∫£m l·∫°nh'\n- 'T√¥i b·ªã ng·ª©a v√† n·ªïi m·∫©n ƒë·ªè'\n- 'V·∫Øc xin COVID-19 c√≥ an to√†n kh√¥ng'\n- 'D·∫•u hi·ªáu c·∫ßn c·∫•p c·ª©u'\n\nB·∫°n quan t√¢m ƒë·∫øn v·∫•n ƒë·ªÅ n√†o?"
        ],
        
        "compliment": [
            "C·∫£m ∆°n b·∫°n! üòä T√¥i c·ªë g·∫Øng cung c·∫•p th√¥ng tin ch√≠nh x√°c nh·∫•t ƒë·ªÉ h·ªó tr·ª£ s·ª©c kh·ªèe c·ªßa b·∫°n. B·∫°n c√≥ c√¢u h·ªèi n√†o kh√°c kh√¥ng?",
            "R·∫•t vui khi ƒë∆∞·ª£c khen! üåü M·ª•c ti√™u c·ªßa t√¥i l√† gi√∫p b·∫°n chƒÉm s√≥c s·ª©c kh·ªèe t·ªët h∆°n. C√≤n g√¨ kh√°c t√¥i c√≥ th·ªÉ gi√∫p ƒë∆∞·ª£c kh√¥ng?",
            "C·∫£m ∆°n l·ªùi khen! üíö S·ª© m·ªánh c·ªßa t√¥i l√† h·ªó tr·ª£ m·ªçi ng∆∞·ªùi v·ªÅ s·ª©c kh·ªèe. B·∫°n c·∫ßn t∆∞ v·∫•n th√™m g√¨ n·ªØa kh√¥ng?"
        ],
        
        "help": [
            "T√¥i s·∫µn s√†ng gi√∫p ƒë·ª°! üÜò\n\nüìù **C√°ch s·ª≠ d·ª•ng:**\n1. **M√¥ t·∫£ tri·ªáu ch·ª©ng:** 'T√¥i b·ªã ho v√† s·ªët'\n2. **H·ªèi v·ªÅ b·ªánh:** 'COVID-19 l√† g√¨?'\n3. **T∆∞ v·∫•n ƒëi·ªÅu tr·ªã:** 'C·∫£m l·∫°nh n√™n l√†m g√¨?'\n4. **Ph√≤ng ng·ª´a:** 'C√°ch tr√°nh d·ªã ·ª©ng'\n\nüéØ **M·∫πo:** H√£y m√¥ t·∫£ c·ª• th·ªÉ tri·ªáu ch·ª©ng ƒë·ªÉ t√¥i ph√¢n t√≠ch ch√≠nh x√°c h∆°n!\n\nB·∫°n mu·ªën th·ª≠ ngay kh√¥ng?",
            "H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng tr·ª£ l√Ω s·ª©c kh·ªèe AI: üìñ\n\nüó£Ô∏è **B·∫°n c√≥ th·ªÉ:**\n- K·ªÉ tri·ªáu ch·ª©ng: 'M√¨nh ƒëau ƒë·∫ßu v√† m·ªát'\n- H·ªèi th√¥ng tin: 'Tri·ªáu ch·ª©ng c√∫m'\n- Xin l·ªùi khuy√™n: 'N√™n l√†m g√¨ khi s·ªët?'\n- H·ªèi ph√≤ng ng·ª´a: 'Tr√°nh COVID-19 nh∆∞ th·∫ø n√†o?'\n\nüí° **L∆∞u √Ω:** T√¥i ch·ªâ t∆∞ v·∫•n c∆° b·∫£n, b·∫°n c·∫ßn ƒëi b√°c sƒ© ƒë·ªÉ ch·∫©n ƒëo√°n ch√≠nh x√°c!"
        ]
    }
    
    if intent in social_responses:
        responses = social_responses[intent]
        # Ch·ªçn random m·ªôt c√¢u tr·∫£ l·ªùi ƒë·ªÉ ƒëa d·∫°ng
        import random
        selected_response = random.choice(responses)
        
        return {
            "question": "",  # Kh√¥ng c·∫ßn ti√™u ƒë·ªÅ cho social responses
            "answer": selected_response
        }
    
    return None


def create_symptom_analysis_response(user_input, ontology_data):
    """T·∫°o c√¢u tr·∫£ l·ªùi th√¥ng minh d·ª±a tr√™n ph√¢n t√≠ch tri·ªáu ch·ª©ng"""
    
    # Tr√≠ch xu·∫•t tri·ªáu ch·ª©ng t·ª´ input
    symptoms = extract_symptoms_from_input(user_input)
    
    if not symptoms:
        return None
    
    # Ph√¢n t√≠ch tri·ªáu ch·ª©ng ƒë·ªÉ t√¨m b·ªánh c√≥ th·ªÉ
    possible_diseases = analyze_symptoms_to_diseases(symptoms)
    
    if not possible_diseases:
        return None
    
    disease_name_map = {
        "covid19": "COVID-19",
        "cold": "c·∫£m l·∫°nh", 
        "flu": "c√∫m",
        "allergy": "d·ªã ·ª©ng"
    }
    
    # T·∫°o c√¢u tr·∫£ l·ªùi
    symptoms_text = ", ".join(symptoms)
    response = f"D·ª±a tr√™n c√°c tri·ªáu ch·ª©ng **{symptoms_text}** m√† b·∫°n m√¥ t·∫£, c√≥ th·ªÉ b·∫°n ƒëang g·∫∑p ph·∫£i:\n\n"
    
    # Hi·ªÉn th·ªã c√°c b·ªánh c√≥ th·ªÉ theo th·ª© t·ª± confidence
    for i, (disease, info) in enumerate(possible_diseases[:3], 1):  # Top 3 diseases
        disease_name = disease_name_map.get(disease, disease)
        confidence_percent = int(info["confidence"] * 100)
        
        response += f"**{i}. {disease_name}** (kh·∫£ nƒÉng: {confidence_percent}%)\n"
        response += f"   - Tri·ªáu ch·ª©ng kh·ªõp: {', '.join(info['matched_symptoms'])}\n"
        
        # L·∫•y th√¥ng tin ƒëi·ªÅu tr·ªã t·ª´ ontology
        if ontology_data and disease in ontology_data:
            ontology = ontology_data[disease]
            if "ontology" in ontology and "instances" in ontology["ontology"]:
                instances = ontology["ontology"]["instances"]
                
                # ƒêi·ªÅu tr·ªã
                if "treatments" in instances and instances["treatments"]:
                    treatments = instances["treatments"][:2]  # Top 2 treatments
                    treatment_names = []
                    for treatment in treatments:
                        name = treatment.get('name', '')
                        if treatment.get('effectiveness'):
                            eff_map = {"High": "hi·ªáu qu·∫£ cao", "Medium": "hi·ªáu qu·∫£ trung b√¨nh", "Low": "hi·ªáu qu·∫£ th·∫•p"}
                            name += f" ({eff_map.get(treatment['effectiveness'], treatment['effectiveness'])})"
                        treatment_names.append(name)
                    response += f"   - ƒêi·ªÅu tr·ªã: {', '.join(treatment_names)}\n"
                
                # Ph√≤ng ng·ª´a
                if "preventions" in instances and instances["preventions"]:
                    preventions = instances["preventions"][:2]  # Top 2 preventions
                    prevention_names = [p.get('name', '') for p in preventions]
                    response += f"   - Ph√≤ng ng·ª´a: {', '.join(prevention_names)}\n"
        
        response += "\n"
    
    # L·ªùi khuy√™n chung
    response += "**üí° L·ªùi khuy√™n:**\n"
    if any(disease == "covid19" for disease, _ in possible_diseases):
        response += "- N√™n l√†m x√©t nghi·ªám COVID-19 ƒë·ªÉ ch·∫©n ƒëo√°n ch√≠nh x√°c\n"
    
    if any(symptom in ["kh√≥ th·ªü", "s·ªët cao", "ƒëau ng·ª±c"] for symptom in symptoms):
        response += "- ‚ö†Ô∏è **C·∫ßn ƒëi kh√°m b√°c sƒ© ngay** do c√≥ tri·ªáu ch·ª©ng nghi√™m tr·ªçng\n"
    else:
        response += "- Ngh·ªâ ng∆°i, u·ªëng nhi·ªÅu n∆∞·ªõc v√† theo d√µi tri·ªáu ch·ª©ng\n"
        response += "- N·∫øu tri·ªáu ch·ª©ng n·∫∑ng h∆°n ho·∫∑c k√©o d√†i, h√£y ƒëi kh√°m b√°c sƒ©\n"
    
    return {
        "question": "",  # Kh√¥ng c·∫ßn ti√™u ƒë·ªÅ, n·ªôi dung ƒë√£ r√µ r√†ng
        "answer": response
    }


def create_intent_based_response(disease_type, user_intent, ontology_data, detected_symptoms=[]):
    """T·∫°o c√¢u tr·∫£ l·ªùi d·ª±a tr√™n intent c·ª• th·ªÉ"""
    if not ontology_data or disease_type not in ontology_data:
        return None
    
    ontology = ontology_data[disease_type]
    disease_name_map = {
        "covid19": "COVID-19",
        "cold": "c·∫£m l·∫°nh", 
        "flu": "c√∫m",
        "allergy": "d·ªã ·ª©ng"
    }
    disease_name = disease_name_map.get(disease_type, disease_type)
    
    if user_intent == "treatment":
        response = f"**üíä C√°ch ƒëi·ªÅu tr·ªã {disease_name}:**\n\n"
        
        # L·∫•y th√¥ng tin ƒëi·ªÅu tr·ªã t·ª´ ontology instances
        if "ontology" in ontology and "instances" in ontology["ontology"]:
            instances = ontology["ontology"]["instances"]
            if "treatments" in instances:
                treatments = instances["treatments"][:3]  # Top 3 treatments
                for i, treatment in enumerate(treatments, 1):
                    response += f"{i}. **{treatment.get('name', '')}**"
                    if treatment.get('type'):
                        response += f" ({treatment['type']})"
                    if treatment.get('effectiveness'):
                        eff_map = {"High": "hi·ªáu qu·∫£ cao", "Medium": "hi·ªáu qu·∫£ trung b√¨nh", "Low": "hi·ªáu qu·∫£ th·∫•p"}
                        response += f" - {eff_map.get(treatment['effectiveness'], treatment['effectiveness'])}"
                    if treatment.get('description'):
                        response += f"\n   {treatment['description']}"
                    response += "\n\n"
        
        return {"question": "", "answer": response.strip()}
    
    elif user_intent == "prevention":
        response = f"**üõ°Ô∏è C√°ch ph√≤ng ng·ª´a {disease_name}:**\n\n"
        
        # L·∫•y th√¥ng tin ph√≤ng ng·ª´a t·ª´ ontology instances
        if "ontology" in ontology and "instances" in ontology["ontology"]:
            instances = ontology["ontology"]["instances"]
            if "preventions" in instances:
                preventions = instances["preventions"][:3]  # Top 3 preventions
                for i, prevention in enumerate(preventions, 1):
                    response += f"{i}. **{prevention.get('name', '')}**"
                    if prevention.get('effectiveness'):
                        eff_map = {"High": "r·∫•t hi·ªáu qu·∫£", "Medium": "hi·ªáu qu·∫£", "Low": "hi·ªáu qu·∫£ h·∫°n ch·∫ø"}
                        response += f" - {eff_map.get(prevention['effectiveness'], prevention['effectiveness'])}"
                    if prevention.get('description'):
                        response += f"\n   {prevention['description']}"
                    response += "\n\n"
        
        return {"question": "", "answer": response.strip()}
    
    elif user_intent == "symptoms":
        response = f"**üìã Tri·ªáu ch·ª©ng {disease_name}:**\n\n"
        
        # L·∫•y th√¥ng tin tri·ªáu ch·ª©ng t·ª´ ontology instances
        if "ontology" in ontology and "instances" in ontology["ontology"]:
            instances = ontology["ontology"]["instances"]
            if "symptoms" in instances:
                symptoms = instances["symptoms"][:5]  # Top 5 symptoms
                for i, symptom in enumerate(symptoms, 1):
                    response += f"{i}. **{symptom.get('name', '')}**"
                    if symptom.get('severity'):
                        response += f" (m·ª©c ƒë·ªô: {symptom['severity']})"
                    if symptom.get('duration'):
                        response += f" - th·ªùi gian: {symptom['duration']}"
                    response += "\n"
        
        return {"question": "", "answer": response.strip()}
    
    return None


# Check for emergency keywords
def is_emergency(text):
    emergency_keywords = [
        "kh√≥ th·ªü nghi√™m tr·ªçng", "ƒëau ng·ª±c", "l√∫ l·∫´n", "m√¥i xanh",
        "m·∫•t √Ω th·ª©c", "c·∫•p c·ª©u", "nguy k·ªãch", "nghi√™m tr·ªçng"
    ]
    text_lower = text.lower()
    return any(keyword in text_lower for keyword in emergency_keywords)


# COVID-19 symptom analysis
def analyze_covid_symptoms(text):
    symptoms = {
        "s·ªët": ["s·ªët", "n√≥ng ng∆∞·ªùi", "·ªõn l·∫°nh"],
        "ho": ["ho", "ho khan", "ho c√≥ ƒë·ªùm"],
        "ƒëau h·ªçng": ["ƒëau h·ªçng", "r√°t h·ªçng", "kh√≥ nu·ªët"],
        "kh√≥ th·ªü": ["kh√≥ th·ªü", "th·ªü kh√≥", "ng·∫°t th·ªü"],
        "m·ªát m·ªèi": ["m·ªát", "m·ªát m·ªèi", "ki·ªát s·ª©c"],
        "ƒëau ƒë·∫ßu": ["ƒëau ƒë·∫ßu", "nh·ª©c ƒë·∫ßu"],
        "m·∫•t v·ªã gi√°c": ["m·∫•t v·ªã", "kh√¥ng c·∫£m nh·∫≠n v·ªã"],
        "m·∫•t kh·ª©u gi√°c": ["m·∫•t m√πi", "kh√¥ng ng·ª≠i ƒë∆∞·ª£c"]
    }

    detected_symptoms = []
    text_lower = text.lower()

    for symptom, keywords in symptoms.items():
        if any(keyword in text_lower for keyword in keywords):
            detected_symptoms.append(symptom)

    return detected_symptoms


# Risk assessment based on symptoms
def assess_covid_risk(symptoms):
    if not symptoms:
        return "th·∫•p", 0.2

    high_risk_symptoms = ["kh√≥ th·ªü", "ƒëau ng·ª±c", "s·ªët cao"]
    medium_risk_symptoms = ["s·ªët", "ho", "ƒëau h·ªçng"]

    risk_score = 0
    for symptom in symptoms:
        if any(hrs in symptom for hrs in high_risk_symptoms):
            risk_score += 0.4
        elif any(mrs in symptom for mrs in medium_risk_symptoms):
            risk_score += 0.2
        else:
            risk_score += 0.1

    if risk_score >= 0.6:
        return "cao", min(risk_score, 0.95)
    elif risk_score >= 0.3:
        return "trung b√¨nh", risk_score
    else:
        return "th·∫•p", risk_score


def format_allergy_info(info, specific_symptom=None):
    if isinstance(info, dict):
        if 'common_symptoms' in info:
            formatted = ""
            if specific_symptom:
                # T√°ch tri·ªáu ch·ª©ng th√†nh c√°c t·ª´ ri√™ng l·∫ª
                symptom_words = specific_symptom.lower().split()
                found_system = None
                found_symptoms = []
                related_symptoms = []

                # T√¨m ki·∫øm trong c√°c h·ªá th·ªëng
                for system in info['common_symptoms']:
                    for symptom in system['symptoms']:
                        symptom_lower = symptom.lower()
                        # Ki·ªÉm tra xem c√≥ t·ª´ kh√≥a n√†o trong tri·ªáu ch·ª©ng c·ª• th·ªÉ kh·ªõp v·ªõi tri·ªáu ch·ª©ng trong h·ªá th·ªëng kh√¥ng
                        if any(word in symptom_lower for word in symptom_words):
                            found_system = system
                            found_symptoms.append(symptom)
                        elif any(word in symptom_lower for word in symptom_words):
                            related_symptoms.append(symptom)

                if found_system:
                    formatted += f"**Tri·ªáu ch·ª©ng '{specific_symptom}' c√≥ th·ªÉ li√™n quan ƒë·∫øn h·ªá th·ªëng {found_system['system']}:**\n\n"
                    
                    # Th√™m th√¥ng tin v·ªÅ tri·ªáu ch·ª©ng ch√≠nh
                    formatted += "**Tri·ªáu ch·ª©ng ch√≠nh:**\n"
                    for symptom in found_symptoms:
                        formatted += f"- {symptom}\n"
                    formatted += "\n"

                    # Th√™m th√¥ng tin v·ªÅ c√°c tri·ªáu ch·ª©ng li√™n quan
                    if related_symptoms:
                        formatted += "**C√°c tri·ªáu ch·ª©ng li√™n quan c√≥ th·ªÉ g·∫∑p:**\n"
                        for symptom in related_symptoms:
                            formatted += f"- {symptom}\n"
                        formatted += "\n"

                    # Th√™m th√¥ng tin v·ªÅ c√°c tri·ªáu ch·ª©ng kh√°c c·ªßa h·ªá th·ªëng
                    formatted += f"**C√°c tri·ªáu ch·ª©ng kh√°c c·ªßa h·ªá th·ªëng {found_system['system']}:**\n"
                    for symptom in found_system['symptoms']:
                        if symptom not in found_symptoms and symptom not in related_symptoms:
                            formatted += f"- {symptom}\n"
                    formatted += "\n"

                    # Th√™m th√¥ng tin v·ªÅ ƒëi·ªÅu tr·ªã n·∫øu c√≥
                    if 'approaches' in info.get('treatment', {}):
                        formatted += "**C√°c ph∆∞∆°ng ph√°p ƒëi·ªÅu tr·ªã c√≥ th·ªÉ √°p d·ª•ng:**\n"
                        for approach in info['treatment']['approaches']:
                            formatted += f"- {approach['method']}: {approach['description']}\n"
                else:
                    formatted = f"Kh√¥ng t√¨m th·∫•y th√¥ng tin c·ª• th·ªÉ v·ªÅ tri·ªáu ch·ª©ng '{specific_symptom}'. "
                    formatted += "D∆∞·ªõi ƒë√¢y l√† c√°c tri·ªáu ch·ª©ng d·ªã ·ª©ng ph·ªï bi·∫øn:\n\n"
                    for system in info['common_symptoms']:
                        formatted += f"**{system['system']}:**\n"
                        for symptom in system['symptoms']:
                            formatted += f"- {symptom}\n"
                        formatted += "\n"
            else:
                formatted = "**Tri·ªáu ch·ª©ng d·ªã ·ª©ng theo h·ªá th·ªëng:**\n\n"
                for system in info['common_symptoms']:
                    formatted += f"**{system['system']}:**\n"
                    for symptom in system['symptoms']:
                        formatted += f"- {symptom}\n"
                    formatted += "\n"
            
            if 'note' in info:
                formatted += f"*L∆∞u √Ω: {info['note']}*\n"
            return formatted
    return str(info)

def format_flu_info(info):
    if isinstance(info, dict):
        formatted = ""
        if 'common_symptoms' in info:
            formatted += "**Tri·ªáu ch·ª©ng ph·ªï bi·∫øn:**\n"
            for symptom in info['common_symptoms']:
                formatted += f"- {symptom}\n"
            formatted += "\n"
        if 'less_common_symptoms' in info:
            formatted += "**Tri·ªáu ch·ª©ng √≠t g·∫∑p h∆°n:**\n"
            for symptom in info['less_common_symptoms']:
                formatted += f"- {symptom}\n"
            formatted += "\n"
        if 'duration' in info:
            formatted += f"**Th·ªùi gian b·ªánh:** {info['duration']}\n\n"
        if 'distinction_from_common_cold' in info:
            formatted += f"**Ph√¢n bi·ªát v·ªõi c·∫£m l·∫°nh:** {info['distinction_from_common_cold']}\n"
        return formatted
    return str(info)

def format_cold_info(info):
    if isinstance(info, dict):
        formatted = ""
        if 'definition' in info:
            formatted += f"{info['definition']}\n\n"
        if 'symptoms' in info:
            formatted += "**Tri·ªáu ch·ª©ng:**\n"
            for symptom in info['symptoms']:
                formatted += f"- {symptom}\n"
            formatted += "\n"
        if 'treatment' in info:
            formatted += "**ƒêi·ªÅu tr·ªã:**\n"
            for treatment in info['treatment']:
                formatted += f"- {treatment}\n"
        return formatted
    return str(info)

def format_covid_info(info):
    if isinstance(info, dict):
        formatted = ""
        if 'question' in info and 'answer' in info:
            formatted += f"{info['answer']}\n"
        return formatted
    return str(info)

# Find best matching answer from knowledge base
def find_best_answer(user_input, kb, ontology_data=None):
    if not kb:
        return None, None, []

    best_match = None
    best_score = 0
    matched_disease = None
    detected_symptoms = []

    # Ki·ªÉm tra xem c√≥ ph·∫£i c√¢u h·ªèi v·ªÅ tri·ªáu ch·ª©ng c·ª• th·ªÉ kh√¥ng
    symptom_keywords = ["b·ªã", "c√≥", "tri·ªáu ch·ª©ng", "d·∫•u hi·ªáu", "bi·ªÉu hi·ªán", "ƒëau", "ng·ª©a", "s∆∞ng", "n·ªïi", "m·∫©n", "l·∫°nh", "s·ªët", "ho"]
    specific_symptom = None
    
    # T√¨m t·ª´ kh√≥a tri·ªáu ch·ª©ng trong c√¢u h·ªèi
    for keyword in symptom_keywords:
        if keyword in user_input.lower():
            # T√°ch t·ª´ sau t·ª´ kh√≥a ƒë·ªÉ l·∫•y tri·ªáu ch·ª©ng
            parts = user_input.lower().split(keyword)
            if len(parts) > 1:
                # L·∫•y ph·∫ßn c√≤n l·∫°i c·ªßa c√¢u l√†m tri·ªáu ch·ª©ng
                specific_symptom = parts[1].strip()
                # Lo·∫°i b·ªè c√°c t·ª´ kh√¥ng c·∫ßn thi·∫øt
                specific_symptom = specific_symptom.replace("l√† g√¨", "").replace("?", "").strip()
                break

    # T√¨m ki·∫øm trong t·∫•t c·∫£ c√°c knowledge base
    disease_scores = {}
    disease_matches = {}
    disease_symptoms = {}

    # COVID-19
    if "covid19" in kb:
        covid_score = 0
        covid_match = None
        covid_symptoms = []
        
        covid_categories = kb["covid19"]["categories"]
        for category_key, category in covid_categories.items():
            for item in category["data"]:
                # Check intent matching
                for intent in category.get("intent", []):
                    if intent.lower() in user_input.lower():
                        score = similarity(user_input, intent)
                        if score > covid_score:
                            covid_score = score
                            covid_match = item

                # Check question similarity
                question_score = similarity(user_input, item["question"])
                if question_score > covid_score:
                    covid_score = question_score
                    covid_match = item

                # Check keywords
                for keyword in item.get("keywords", []):
                    if keyword.lower() in user_input.lower():
                        keyword_score = similarity(user_input, keyword) * 0.8
                        if keyword_score > covid_score:
                            covid_score = keyword_score
                            covid_match = item

        # Analyze COVID-19 symptoms
        symptoms = analyze_covid_symptoms(user_input)
        if symptoms:
            covid_symptoms = symptoms
            covid_score += 0.2  # TƒÉng ƒëi·ªÉm n·∫øu ph√°t hi·ªán tri·ªáu ch·ª©ng

        disease_scores["covid19"] = covid_score
        disease_matches["covid19"] = covid_match
        disease_symptoms["covid19"] = covid_symptoms

    # Cold
    if "cold" in kb:
        cold_score = 0
        cold_match = None
        cold_symptoms = []
        
        for intent_type, intents in kb["cold"]["chatbot_intents"].items():
            for intent in intents:
                if intent.lower() in user_input.lower():
                    for category_key, category in kb["cold"]["categories"].items():
                        if intent_type in category_key:
                            response = {
                                "question": f"Th√¥ng tin v·ªÅ {intent_type} c·ªßa b·ªánh c·∫£m l·∫°nh",
                                "answer": format_cold_info(category)
                            }
                            score = similarity(user_input, intent)
                            if score > cold_score:
                                cold_score = score
                                cold_match = response

        # Analyze cold symptoms
        cold_symptom_list = ["s·ªï m≈©i", "ngh·∫πt m≈©i", "ƒëau h·ªçng", "ho", "h·∫Øt h∆°i", "ƒëau ƒë·∫ßu nh·∫π", "s·ªët nh·∫π", "l·∫°nh", "·ªõn l·∫°nh"]
        for symptom in cold_symptom_list:
            if symptom in user_input.lower():
                cold_symptoms.append(symptom)
                cold_score += 0.2  # TƒÉng ƒëi·ªÉm n·∫øu ph√°t hi·ªán tri·ªáu ch·ª©ng

        disease_scores["cold"] = cold_score
        disease_matches["cold"] = cold_match
        disease_symptoms["cold"] = cold_symptoms

    # Flu
    if "flu" in kb:
        flu_score = 0
        flu_match = None
        flu_symptoms = []
        
        for topic in kb["flu"]["topics"]:
            # Check topic name
            topic_score = similarity(user_input, topic["name"])
            if topic_score > flu_score:
                flu_score = topic_score
                flu_match = {
                    "question": topic["name"],
                    "answer": format_flu_info(topic["information"])
                }

            # Check information content
            if isinstance(topic["information"], dict):
                for key, value in topic["information"].items():
                    if isinstance(value, str):
                        content_score = similarity(user_input, value)
                        if content_score > flu_score:
                            flu_score = content_score
                            flu_match = {
                                "question": topic["name"],
                                "answer": format_flu_info(topic["information"])
                            }

        # Analyze flu symptoms
        flu_symptom_list = ["s·ªët cao", "·ªõn l·∫°nh", "ƒëau c∆°", "m·ªát m·ªèi", "ho", "ƒëau h·ªçng", "ƒëau ƒë·∫ßu", "s·ªï m≈©i", "l·∫°nh"]
        for symptom in flu_symptom_list:
            if symptom in user_input.lower():
                flu_symptoms.append(symptom)
                flu_score += 0.2  # TƒÉng ƒëi·ªÉm n·∫øu ph√°t hi·ªán tri·ªáu ch·ª©ng

        disease_scores["flu"] = flu_score
        disease_matches["flu"] = flu_match
        disease_symptoms["flu"] = flu_symptoms

    # Allergy
    if "allergy" in kb:
        allergy_score = 0
        allergy_match = None
        allergy_symptoms = []
        
        for topic in kb["allergy"]["topics"]:
            # Check topic name
            topic_score = similarity(user_input, topic["name"])
            if topic_score > allergy_score:
                allergy_score = topic_score
                allergy_match = {
                    "question": topic["name"],
                    "answer": format_allergy_info(topic["information"], specific_symptom)
                }

            # Check information content
            if isinstance(topic["information"], dict):
                for key, value in topic["information"].items():
                    if isinstance(value, str):
                        content_score = similarity(user_input, value)
                        if content_score > allergy_score:
                            allergy_score = content_score
                            allergy_match = {
                                "question": topic["name"],
                                "answer": format_allergy_info(topic["information"], specific_symptom)
                            }

        # Analyze allergy symptoms
        allergy_symptom_list = ["h·∫Øt h∆°i", "ng·ª©a m≈©i", "ch·∫£y n∆∞·ªõc m≈©i", "ng·ª©a m·∫Øt", "ph√°t ban", "n·ªïi m·ªÅ ƒëay", "ng·ª©a da", "ng·ª©a", "m·∫©n ng·ª©a", "n·ªïi m·ª•n n∆∞·ªõc", "bong tr√≥c da", "ch√†m"]
        for symptom in allergy_symptom_list:
            if symptom in user_input.lower():
                allergy_symptoms.append(symptom)
                allergy_score += 0.2  # TƒÉng ƒëi·ªÉm n·∫øu ph√°t hi·ªán tri·ªáu ch·ª©ng

        disease_scores["allergy"] = allergy_score
        disease_matches["allergy"] = allergy_match
        disease_symptoms["allergy"] = allergy_symptoms

    # T√¨m b·ªánh c√≥ ƒëi·ªÉm cao nh·∫•t t·ª´ knowledge base
    best_disease = max(disease_scores.items(), key=lambda x: x[1])
    kb_best_match = None
    kb_best_disease = None
    kb_symptoms = []
    
    if best_disease[1] > 0.3:
        kb_best_match = disease_matches[best_disease[0]]
        kb_best_disease = best_disease[0]
        kb_symptoms = disease_symptoms[best_disease[0]]
    
    # T√≠ch h·ª£p k·∫øt qu·∫£ t·ª´ ontology n·∫øu c√≥
    ontology_best_match = None
    ontology_best_score = 0
    ontology_disease = None
    
    if ontology_data:
        user_intent = analyze_user_intent(user_input)
        detected_disease = detect_disease_from_input(user_input)
        
        # ∆Øu ti√™n cao nh·∫•t: Social responses (ch√†o h·ªèi, c·∫£m ∆°n, etc.)
        social_intents = ["greeting", "goodbye", "thanks", "how_are_you", "what_can_you_do", 
                         "ask_more", "compliment", "help"]
        
        if user_intent in social_intents:
            social_response = create_social_response(user_intent, user_input)
            if social_response:
                ontology_best_match = social_response
                ontology_best_score = 0.99  # Score cao nh·∫•t ƒë·ªÉ ∆∞u ti√™n social responses
                ontology_disease = "social"
        
        # ∆Øu ti√™n th·ª© 2: Ph√¢n t√≠ch tri·ªáu ch·ª©ng t·ª´ ng√¥n ng·ªØ t·ª± nhi√™n
        if not ontology_best_match and user_intent == "symptom_analysis":
            symptom_response = create_symptom_analysis_response(user_input, ontology_data)
            if symptom_response:
                ontology_best_match = symptom_response
                ontology_best_score = 0.98  # Score r·∫•t cao ƒë·ªÉ ∆∞u ti√™n symptom analysis
                ontology_disease = "symptom_analysis"
        
        # N·∫øu c√≥ intent r√µ r√†ng v√† detect ƒë∆∞·ª£c disease, t·∫°o c√¢u tr·∫£ l·ªùi tr·ª±c ti·∫øp
        if not ontology_best_match:
            target_disease = detected_disease if detected_disease else (best_disease[0] if best_disease[1] > 0.2 else None)
            
            if user_intent in ["treatment", "prevention", "symptoms"] and target_disease:
                intent_response = create_intent_based_response(target_disease, user_intent, ontology_data, disease_symptoms.get(target_disease, []))
                if intent_response:
                    ontology_best_match = intent_response
                    ontology_best_score = 0.95  # Score cao ƒë·ªÉ ∆∞u ti√™n intent-based response
                    ontology_disease = target_disease
        
        # Fallback: T√¨m ki·∫øm trong t·∫•t c·∫£ c√°c ontology nh∆∞ c≈©
        if not ontology_best_match:
            for disease_type in ["covid19", "cold", "flu", "allergy"]:
                onto_answer, onto_score = extract_from_ontology(disease_type, user_input, ontology_data)
                if onto_answer and onto_score > ontology_best_score:
                    ontology_best_score = onto_score
                    ontology_best_match = onto_answer
                    ontology_disease = disease_type
    
    # Quy·∫øt ƒë·ªãnh k·∫øt qu·∫£ t·ªët nh·∫•t
    if ontology_best_score > best_disease[1] and ontology_best_score > 0.3:
        # Ontology c√≥ k·∫øt qu·∫£ t·ªët h∆°n
        return ontology_best_match, ontology_disease, []
    elif kb_best_match:
        # Knowledge base c√≥ k·∫øt qu·∫£ t·ªët h∆°n ho·∫∑c b·∫±ng
        return kb_best_match, kb_best_disease, kb_symptoms
    elif ontology_best_match and ontology_best_score > 0.2:
        # D√πng ontology nh∆∞ backup n·∫øu KB kh√¥ng c√≥ k·∫øt qu·∫£ t·ªët
        return ontology_best_match, ontology_disease, []
    
    return None, None, []


# Generate COVID-19 specific recommendations
def generate_covid_recommendations(symptoms, risk_level):
    base_recommendations = [
        "üè† C√°ch ly t·∫°i nh√† √≠t nh·∫•t 5 ng√†y",
        "üò∑ ƒêeo kh·∫©u trang khi ti·∫øp x√∫c v·ªõi ng∆∞·ªùi kh√°c",
        "üö∞ U·ªëng nhi·ªÅu n∆∞·ªõc, ngh·ªâ ng∆°i ƒë·∫ßy ƒë·ªß",
        "üå°Ô∏è Theo d√µi th√¢n nhi·ªát th∆∞·ªùng xuy√™n"
    ]

    if risk_level == "cao":
        base_recommendations.extend([
            "üè• Li√™n h·ªá b√°c sƒ© ngay l·∫≠p t·ª©c",
            "üìû G·ªçi hotline COVID-19: 19009095",
            "‚ö†Ô∏è ƒê·∫øn b·ªánh vi·ªán n·∫øu kh√≥ th·ªü tƒÉng"
        ])
    elif risk_level == "trung b√¨nh":
        base_recommendations.extend([
            "üìû Li√™n h·ªá tr·∫°m y t·∫ø ƒë·ªãa ph∆∞∆°ng",
            "üß™ Xem x√©t l√†m x√©t nghi·ªám COVID-19"
        ])

    return base_recommendations


# Main UI
def main():
    st.title("üè• H·ªá th·ªëng T∆∞ v·∫•n S·ª©c kh·ªèe AI")
    st.markdown("üí¨ **H·ªèi ƒë√°p th√¥ng tin v·ªÅ c√°c b·ªánh th∆∞·ªùng g·∫∑p v·ªõi AI**")

    # Load knowledge base v√† ontology
    kb = load_knowledge_base()
    ontology_data = load_ontology_data()
    
    if not kb:
        st.stop()
    
    # Hi·ªÉn th·ªã tr·∫°ng th√°i h·ªá th·ªëng (ch·ªâ cho developer, ·∫©n kh·ªèi ng∆∞·ªùi d√πng cu·ªëi)
    if ontology_data:
        st.success("‚úÖ H·ªá th·ªëng AI ƒë√£ s·∫µn s√†ng v·ªõi ƒë·∫ßy ƒë·ªß t√≠nh nƒÉng!")
    else:
        st.warning("‚ö†Ô∏è ƒêang ch·∫°y ·ªü ch·∫ø ƒë·ªô c∆° b·∫£n. M·ªôt s·ªë t√≠nh nƒÉng n√¢ng cao c√≥ th·ªÉ kh√¥ng kh·∫£ d·ª•ng.")

    # Sidebar with quick info
    with st.sidebar:
        st.header("üìã Th√¥ng tin nhanh")
        st.markdown("""
        **Hotline kh·∫©n c·∫•p:**
        - üö® C·∫•p c·ª©u: **115**
        - üìû COVID-19: **19009095**
        - üè• B·ªô Y t·∫ø: **19003228**

        **Tri·ªáu ch·ª©ng c·∫ßn c·∫•p c·ª©u:**
        - Kh√≥ th·ªü nghi√™m tr·ªçng
        - ƒêau ng·ª±c dai d·∫≥ng
        - M√¥i xanh t√≠m
        - L√∫ l·∫´n, m·∫•t √Ω th·ª©c
        - S·ªëc ph·∫£n v·ªá (d·ªã ·ª©ng)
        - S·ªët cao k√©o d√†i
        """)

        st.markdown("---")
        st.markdown("**Ph√≤ng ng·ª´a c∆° b·∫£n:**")
        st.markdown("- üò∑ ƒêeo kh·∫©u trang khi c·∫ßn")
        st.markdown("- üßº R·ª≠a tay th∆∞·ªùng xuy√™n")
        st.markdown("- üìè Gi·ªØ kho·∫£ng c√°ch an to√†n")
        st.markdown("- üíâ Ti√™m v·∫Øc xin ƒë·∫ßy ƒë·ªß")
        st.markdown("- üè† Gi·ªØ ·∫•m c∆° th·ªÉ")
        st.markdown("- ü•ó ƒÇn u·ªëng ƒë·∫ßy ƒë·ªß dinh d∆∞·ª°ng")
        st.markdown("- üåø Tr√°nh c√°c t√°c nh√¢n g√¢y d·ªã ·ª©ng")
        
        st.markdown("---")
        st.markdown("**H·ªá th·ªëng h·ªó tr·ª£:**")
        if ontology_data:
            st.markdown("- üß† **AI n√¢ng cao** - Ph√¢n t√≠ch chuy√™n s√¢u")
            st.markdown("- üìö **C∆° s·ªü d·ªØ li·ªáu** - Th√¥ng tin y t·∫ø")
            st.markdown("- üîç **T√¨m ki·∫øm th√¥ng minh** - K·∫øt qu·∫£ ch√≠nh x√°c")
        else:
            st.markdown("- üìö **C∆° s·ªü d·ªØ li·ªáu** - Th√¥ng tin y t·∫ø")
            st.markdown("- ‚ö†Ô∏è **AI n√¢ng cao** - ƒêang t·∫£i...")

    # Initialize chat history
    if "chat_history" not in st.session_state:
        st.session_state.chat_history = []
        # Add welcome message
        welcome_msg = "Xin ch√†o! üëã T√¥i l√† tr·ª£ l√Ω s·ª©c kh·ªèe AI th√¥ng minh.\n\nüîç **T√¥i c√≥ th·ªÉ gi√∫p b·∫°n:**\n- Ph√¢n t√≠ch tri·ªáu ch·ª©ng (VD: 'T√¥i b·ªã ho v√† s·ªët')\n- T∆∞ v·∫•n ƒëi·ªÅu tr·ªã c√°c b·ªánh th∆∞·ªùng g·∫∑p\n- H∆∞·ªõng d·∫´n ph√≤ng ng·ª´a COVID-19, c√∫m, c·∫£m l·∫°nh, d·ªã ·ª©ng\n- C·∫£nh b√°o khi c·∫ßn ƒëi b√°c sƒ© ngay\n\nüí¨ H√£y m√¥ t·∫£ tri·ªáu ch·ª©ng ho·∫∑c h·ªèi c√¢u h·ªèi c·ªßa b·∫°n!"
        st.session_state.chat_history.append(("AI", welcome_msg))

    # Clear chat button
    if st.button("üóëÔ∏è X√≥a cu·ªôc tr√≤ chuy·ªán"):
        # X√≥a l·ªãch s·ª≠ chat
        st.session_state.chat_history = []
        # Th√™m l·∫°i tin nh·∫Øn ch√†o m·ª´ng
        welcome_msg = "Xin ch√†o! üëã T√¥i l√† tr·ª£ l√Ω s·ª©c kh·ªèe AI th√¥ng minh.\n\nüîç **T√¥i c√≥ th·ªÉ gi√∫p b·∫°n:**\n- Ph√¢n t√≠ch tri·ªáu ch·ª©ng (VD: 'T√¥i b·ªã ho v√† s·ªët')\n- T∆∞ v·∫•n ƒëi·ªÅu tr·ªã c√°c b·ªánh th∆∞·ªùng g·∫∑p\n- H∆∞·ªõng d·∫´n ph√≤ng ng·ª´a COVID-19, c√∫m, c·∫£m l·∫°nh, d·ªã ·ª©ng\n- C·∫£nh b√°o khi c·∫ßn ƒëi b√°c sƒ© ngay\n\nüí¨ H√£y m√¥ t·∫£ tri·ªáu ch·ª©ng ho·∫∑c h·ªèi c√¢u h·ªèi c·ªßa b·∫°n!"
        st.session_state.chat_history.append(("AI", welcome_msg))
        # X√≥a input c·ªßa ng∆∞·ªùi d√πng
        st.session_state.user_input = ""
        # L√†m m·ªõi trang
        st.rerun()

    # Chat input
    user_input = st.text_input("üí≠ B·∫°n mu·ªën h·ªèi g√¨ v·ªÅ s·ª©c kh·ªèe?", key="user_input")

    # Process user input
    if user_input:
        # Add user message to chat
        st.session_state.chat_history.append(("User", user_input))

        # Check for emergency
        if is_emergency(user_input):
            # L·∫•y th√¥ng tin c·∫•p c·ª©u t·ª´ ontology n·∫øu c√≥
            emergency_response = "‚ö†Ô∏è **C·∫¢NH B√ÅO KH·∫®N C·∫§P!**\n\nVui l√≤ng g·ªçi ngay s·ªë c·∫•p c·ª©u 115 ho·∫∑c ƒë·∫øn b·ªánh vi·ªán g·∫ßn nh·∫•t n·∫øu b·∫°n ƒëang g·∫∑p c√°c tri·ªáu ch·ª©ng nghi√™m tr·ªçng nh∆∞ kh√≥ th·ªü, ƒëau ng·ª±c, m√¥i xanh t√≠m, ho·∫∑c m·∫•t √Ω th·ª©c."
            
            # Th√™m th√¥ng tin c·∫•p c·ª©u t·ª´ ontology
            if ontology_data:
                for disease_type in ["covid19", "cold", "flu", "allergy"]:
                    emergency_onto = get_emergency_response(disease_type, ontology_data)
                    if emergency_onto:
                        emergency_response += f"\n\n{emergency_onto}"
                        break
            
            st.session_state.chat_history.append(("AI", emergency_response))
        else:
            # Find answer from knowledge base v√† ontology
            answer, matched_disease, detected_symptoms = find_best_answer(user_input, kb, ontology_data)

            if answer:
                response = f"**üìã {answer['question']}**\n\n{answer['answer']}"

                # Add disease-specific analysis if symptoms detected
                if detected_symptoms:
                    if matched_disease == "covid19":
                        risk_level, confidence = assess_covid_risk(detected_symptoms)
                        response += f"\n\n**üîç Ph√¢n t√≠ch tri·ªáu ch·ª©ng COVID-19:**"
                        response += f"\n- Tri·ªáu ch·ª©ng ph√°t hi·ªán: {', '.join(detected_symptoms)}"
                        response += f"\n- M·ª©c ƒë·ªô nguy c∆°: **{risk_level}** ({int(confidence * 100)}%)"

                        # Add COVID-19 recommendations
                        recommendations = generate_covid_recommendations(detected_symptoms, risk_level)
                        response += f"\n\n**üíä Khuy·∫øn ngh·ªã cho COVID-19:**"
                        for rec in recommendations:
                            response += f"\n{rec}"
                    elif matched_disease == "cold":
                        response += f"\n\n**üîç Ph√¢n t√≠ch tri·ªáu ch·ª©ng c·∫£m l·∫°nh:**"
                        response += f"\n- Tri·ªáu ch·ª©ng ph√°t hi·ªán: {', '.join(detected_symptoms)}"
                        response += f"\n- Khuy·∫øn ngh·ªã: Ngh·ªâ ng∆°i, u·ªëng nhi·ªÅu n∆∞·ªõc, gi·ªØ ·∫•m c∆° th·ªÉ"
                    elif matched_disease == "flu":
                        response += f"\n\n**üîç Ph√¢n t√≠ch tri·ªáu ch·ª©ng c√∫m:**"
                        response += f"\n- Tri·ªáu ch·ª©ng ph√°t hi·ªán: {', '.join(detected_symptoms)}"
                        response += f"\n- Khuy·∫øn ngh·ªã: Ngh·ªâ ng∆°i, u·ªëng nhi·ªÅu n∆∞·ªõc, d√πng thu·ªëc h·∫° s·ªët n·∫øu c·∫ßn"
                    elif matched_disease == "allergy":
                        response += f"\n\n**üîç Ph√¢n t√≠ch tri·ªáu ch·ª©ng d·ªã ·ª©ng:**"
                        response += f"\n- Tri·ªáu ch·ª©ng ph√°t hi·ªán: {', '.join(detected_symptoms)}"
                        response += f"\n- Khuy·∫øn ngh·ªã: Tr√°nh ti·∫øp x√∫c v·ªõi t√°c nh√¢n g√¢y d·ªã ·ª©ng, d√πng thu·ªëc kh√°ng histamine n·∫øu c·∫ßn"
                
                # Th√™m th√¥ng tin t·ª´ ontology m·ªôt c√°ch t·ª± nhi√™n (ch·ªâ khi kh√¥ng ph·∫£i symptom analysis ho·∫∑c social)
                if ontology_data and matched_disease and matched_disease not in ["symptom_analysis", "social"]:
                    ontology_analysis = get_ontology_symptom_analysis(matched_disease, detected_symptoms, ontology_data)
                    
                    if ontology_analysis:
                        # T√≠ch h·ª£p th√¥ng tin ƒëi·ªÅu tr·ªã t·ª´ ontology
                        if "treatments" in ontology_analysis and ontology_analysis["treatments"]:
                            treatment_info = []
                            for treatment in ontology_analysis["treatments"][:2]:  # Ch·ªâ l·∫•y 2 ph∆∞∆°ng ph√°p h√†ng ƒë·∫ßu
                                if treatment['effectiveness'] and treatment['effectiveness'] != "":
                                    effectiveness_map = {"High": "cao", "Medium": "trung b√¨nh", "Low": "th·∫•p"}
                                    eff_text = effectiveness_map.get(treatment['effectiveness'], treatment['effectiveness'])
                                    treatment_info.append(f"{treatment['name']} (hi·ªáu qu·∫£ {eff_text})")
                                else:
                                    treatment_info.append(treatment['name'])
                            
                            if treatment_info:
                                response += f"\n\n**üíä C√°c ph∆∞∆°ng ph√°p ƒëi·ªÅu tr·ªã khuy·∫øn ngh·ªã:** {', '.join(treatment_info)}."
                        
                        # T√≠ch h·ª£p th√¥ng tin ph√≤ng ng·ª´a t·ª´ ontology
                        if "preventions" in ontology_analysis and ontology_analysis["preventions"]:
                            prevention_info = []
                            for prevention in ontology_analysis["preventions"][:2]:  # Ch·ªâ l·∫•y 2 bi·ªán ph√°p h√†ng ƒë·∫ßu
                                if prevention['effectiveness'] and prevention['effectiveness'] != "":
                                    effectiveness_map = {"High": "r·∫•t hi·ªáu qu·∫£", "Medium": "hi·ªáu qu·∫£", "Low": "hi·ªáu qu·∫£ h·∫°n ch·∫ø"}
                                    eff_text = effectiveness_map.get(prevention['effectiveness'], prevention['effectiveness'])
                                    prevention_info.append(f"{prevention['name']} ({eff_text})")
                                else:
                                    prevention_info.append(prevention['name'])
                            
                            if prevention_info:
                                response += f"\n\n**üõ°Ô∏è Bi·ªán ph√°p ph√≤ng ng·ª´a quan tr·ªçng:** {', '.join(prevention_info)}."
                        
                        # Hi·ªÉn th·ªã th√¥ng tin tri·ªáu ch·ª©ng chi ti·∫øt n·∫øu c√≥
                        if "matched_symptoms" in ontology_analysis and ontology_analysis["matched_symptoms"]:
                            detailed_symptoms = []
                            for symp in ontology_analysis["matched_symptoms"][:2]:  # Ch·ªâ hi·ªÉn th·ªã 2 tri·ªáu ch·ª©ng chi ti·∫øt nh·∫•t
                                symptom_detail = symp['name']
                                if symp['duration'] != "Unknown" and symp['duration']:
                                    symptom_detail += f" (th∆∞·ªùng k√©o d√†i {symp['duration']})"
                                detailed_symptoms.append(symptom_detail)
                            
                            if detailed_symptoms:
                                response += f"\n\n**üìã Th√¥ng tin b·ªï sung v·ªÅ tri·ªáu ch·ª©ng:** {', '.join(detailed_symptoms)}."

                # Add disclaimer (ch·ªâ cho medical responses)
                if matched_disease not in ["social"]:
                    response += f"\n\n‚ö†Ô∏è L∆∞u √Ω: Th√¥ng tin t√¥i cung c·∫•p ch·ªâ mang t√≠nh ch·∫•t tham kh·∫£o. ƒê·ªÉ ƒë∆∞·ª£c ch·∫©n ƒëo√°n v√† ƒëi·ªÅu tr·ªã ch√≠nh x√°c, b·∫°n c·∫ßn tham kh·∫£o √Ω ki·∫øn b√°c sƒ© ho·∫∑c c∆° s·ªü y t·∫ø c√≥ th·∫©m quy·ªÅn."

            else:
                # Fallback response
                response = "Xin l·ªói, t√¥i ch∆∞a c√≥ ƒë·ªß th√¥ng tin ƒë·ªÉ tr·∫£ l·ªùi c√¢u h·ªèi c·ªßa b·∫°n. Vui l√≤ng th·ª≠ h·ªèi l·∫°i theo c√°ch kh√°c ho·∫∑c li√™n h·ªá v·ªõi b√°c sƒ© ƒë·ªÉ ƒë∆∞·ª£c t∆∞ v·∫•n chi ti·∫øt h∆°n."

            st.session_state.chat_history.append(("AI", response))

    # Display chat history
    st.markdown("### üí¨ Cu·ªôc tr√≤ chuy·ªán")
    chat_container = st.container()

    with chat_container:
        for i, (speaker, message) in enumerate(st.session_state.chat_history):
            if speaker == "User":
                st.markdown(
                    f"""
                    <div style="text-align: right; margin: 10px 0;">
                        <div style="display: inline-block; background-color: #007bff; color: white; 
                                    padding: 10px 15px; border-radius: 15px 15px 5px 15px; max-width: 70%;">
                            <strong>üë§ B·∫°n:</strong> {message}
                        </div>
                    </div>
                    """,
                    unsafe_allow_html=True
                )
            else:
                st.markdown(
                    f"""
                    <div style="text-align: left; margin: 10px 0;">
                        <div style="display: inline-block; background-color: #f8f9fa; color: black; 
                                    padding: 10px 15px; border-radius: 15px 15px 15px 5px; max-width: 70%;
                                    border-left: 4px solid #28a745;">
                            <strong>ü§ñ AI:</strong><br>{message}
                        </div>
                    </div>
                    """,
                    unsafe_allow_html=True
                )

    # Quick action buttons
    st.markdown("### üöÄ C√¢u h·ªèi g·ª£i √Ω")
    
    quick_questions = [
        "Xin ch√†o! üëã",
        "B·∫°n c√≥ th·ªÉ l√†m g√¨?",
        "T√¥i b·ªã ho v√† s·ªët",
        "Tri·ªáu ch·ª©ng c√∫m l√† g√¨?",
        "C√°ch ph√≤ng ng·ª´a d·ªã ·ª©ng?",
        "ƒêi·ªÅu tr·ªã c·∫£m l·∫°nh t·∫°i nh√†?",
        "COVID-19 l√† g√¨?",
        "C·∫£m ∆°n b·∫°n! üíö"
    ]

    # Hi·ªÉn th·ªã c√¢u h·ªèi theo 2 h√†ng, m·ªói h√†ng 4 c·ªôt
    col1, col2, col3, col4 = st.columns(4)
    cols_row1 = [col1, col2, col3, col4]
    
    for i, question in enumerate(quick_questions[:4]):
        if cols_row1[i].button(question, key=f"quick_{i}"):
            st.session_state.chat_history.append(("User", question))
            st.rerun()
    
    # H√†ng th·ª© 2
    if len(quick_questions) > 4:
        col5, col6, col7, col8 = st.columns(4)
        cols_row2 = [col5, col6, col7, col8]
        
        for i, question in enumerate(quick_questions[4:8]):
            if cols_row2[i].button(question, key=f"quick_{i+4}"):
                st.session_state.chat_history.append(("User", question))
                st.rerun()


if __name__ == "__main__":
    main()