import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.model_selection import train_test_split, StratifiedShuffleSplit, GridSearchCV, cross_val_score
from sklearn.preprocessing import LabelEncoder, RobustScaler, StandardScaler
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, top_k_accuracy_score
from sklearn.utils.class_weight import compute_class_weight
import pickle
import os
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

print("üöÄ S·ª≠ d·ª•ng Advanced Machine Learning v·ªõi Python 3.13.2")
print("üß† Models: RandomForest + GradientBoosting + MLPClassifier + Ensemble")

class ProfessionalHealthcareChatbot:
    def __init__(self):
        self.condition_model = None
        self.medication_model = None
        self.label_encoders = {}
        self.scaler = RobustScaler()  # Robust h∆°n StandardScaler
        self.condition_encoder = LabelEncoder()
        self.medication_encoder = LabelEncoder()
        
        # Feature engineering - th√™m nhi·ªÅu features h∆°n
        self.feature_columns = [
            'Age', 'Gender', 'Blood Type', 'Admission Type', 
            'Test Results', 'Age_Group', 'Risk_Score'
        ]
        
        # Th√¥ng tin training
        self.training_history = None
        self.model_metrics = {}
        
    def load_and_preprocess_data(self, file_path, use_full_data=True):
        """T·∫£i v√† x·ª≠ l√Ω to√†n b·ªô d·ªØ li·ªáu healthcare"""
        print("üîÑ ƒêang t·∫£i d·ªØ li·ªáu healthcare...")
        
        try:
            if use_full_data:
                # T·∫£i to√†n b·ªô d·ªØ li·ªáu
                df = pd.read_csv(file_path)
                print(f"üìä ƒê√£ t·∫£i TO√ÄN B·ªò d·ªØ li·ªáu: {len(df)} b·∫£n ghi")
            else:
                # T·∫£i sample ƒë·ªÉ test nhanh
                df = pd.read_csv(file_path, nrows=5000)
                print(f"üìä ƒê√£ t·∫£i sample: {len(df)} b·∫£n ghi")
            
            # Th·ªëng k√™ d·ªØ li·ªáu ban ƒë·∫ßu
            print(f"üìã K√≠ch th∆∞·ªõc d·ªØ li·ªáu: {df.shape}")
            print(f"üìã C√°c c·ªôt: {list(df.columns)}")
            print(f"üìã D·ªØ li·ªáu thi·∫øu: {df.isnull().sum().sum()} cells")
            
            # L√†m s·∫°ch d·ªØ li·ªáu
            initial_count = len(df)
            df = df.dropna()
            final_count = len(df)
            print(f"üìä Sau khi lo·∫°i b·ªè d·ªØ li·ªáu thi·∫øu: {final_count} b·∫£n ghi ({initial_count - final_count} ƒë√£ b·ªã lo·∫°i b·ªè)")
            
            # Chu·∫©n h√≥a t√™n c·ªôt
            df.columns = df.columns.str.strip()
            
            # Th·ªëng k√™ ph√¢n b·ªë d·ªØ li·ªáu
            print("\nüìà PH√ÇN B·ªê D·ªÆ LI·ªÜU:")
            print(f"   ‚Ä¢ S·ªë l∆∞·ª£ng b·ªánh kh√°c nhau: {df['Medical Condition'].nunique()}")
            print(f"   ‚Ä¢ S·ªë l∆∞·ª£ng thu·ªëc kh√°c nhau: {df['Medication'].nunique()}")
            print(f"   ‚Ä¢ ƒê·ªô tu·ªïi: {df['Age'].min()}-{df['Age'].max()} (trung b√¨nh: {df['Age'].mean():.1f})")
            print(f"   ‚Ä¢ Gi·ªõi t√≠nh: {df['Gender'].value_counts().to_dict()}")
            
            return df
            
        except Exception as e:
            print(f"‚ùå L·ªói t·∫£i d·ªØ li·ªáu: {str(e)}")
            return None
    
    def feature_engineering(self, df):
        """T·∫°o th√™m c√°c features t·ª´ d·ªØ li·ªáu g·ªëc"""
        print("üîß ƒêang th·ª±c hi·ªán feature engineering...")
        
        df_enhanced = df.copy()
        
        # 1. T·∫°o Age Groups
        df_enhanced['Age_Group'] = pd.cut(
            df_enhanced['Age'], 
            bins=[0, 18, 35, 50, 65, 100], 
            labels=['Child', 'Young_Adult', 'Adult', 'Middle_Age', 'Senior']
        )
        
        # 2. T·∫°o Risk Score d·ª±a tr√™n nhi·ªÅu y·∫øu t·ªë
        risk_score = 0
        
        # Risk t·ª´ tu·ªïi
        risk_score += (df_enhanced['Age'] / 100) * 0.3
        
        # Risk t·ª´ k·∫øt qu·∫£ x√©t nghi·ªám
        risk_score += df_enhanced['Test Results'].map({
            'Normal': 0.1, 'Inconclusive': 0.5, 'Abnormal': 0.9
        }).fillna(0.5) * 0.4
        
        # Risk t·ª´ lo·∫°i nh·∫≠p vi·ªán
        risk_score += df_enhanced['Admission Type'].map({
            'Elective': 0.2, 'Urgent': 0.6, 'Emergency': 1.0
        }).fillna(0.5) * 0.3
        
        df_enhanced['Risk_Score'] = risk_score
        
        print(f"‚úÖ ƒê√£ t·∫°o th√™m {len(['Age_Group', 'Risk_Score'])} features")
        return df_enhanced
    
    def encode_features(self, df):
        """M√£ h√≥a c√°c ƒë·∫∑c tr∆∞ng categorical v·ªõi k·ªπ thu·∫≠t ti√™n ti·∫øn"""
        print("üîÑ ƒêang m√£ h√≥a d·ªØ li·ªáu v·ªõi k·ªπ thu·∫≠t ti√™n ti·∫øn...")
        
        df_encoded = df.copy()
        
        # M√£ h√≥a categorical columns
        categorical_columns = ['Gender', 'Blood Type', 'Admission Type', 'Test Results', 'Age_Group']
        
        for col in categorical_columns:
            if col in df_encoded.columns:
                le = LabelEncoder()
                df_encoded[col] = le.fit_transform(df_encoded[col].astype(str))
                self.label_encoders[col] = le
                print(f"   ‚úì Encoded {col}: {len(le.classes_)} classes")
        
        # Chu·∫©n h√≥a numerical features v·ªõi RobustScaler
        numerical_cols = ['Age', 'Risk_Score']
        df_encoded[numerical_cols] = self.scaler.fit_transform(df_encoded[numerical_cols])
        
        return df_encoded
    
    def prepare_training_data(self, df_encoded):
        """Chu·∫©n b·ªã d·ªØ li·ªáu training v·ªõi class balancing"""
        print("üìä ƒêang chu·∫©n b·ªã d·ªØ li·ªáu training...")
        
        # Features (X)
        X = df_encoded[self.feature_columns].values
        print(f"   ‚úì Features shape: {X.shape}")
        
        # Targets (y)
        y_condition = self.condition_encoder.fit_transform(df_encoded['Medical Condition'])
        y_medication = self.medication_encoder.fit_transform(df_encoded['Medication'])
        
        print(f"   ‚úì Condition classes: {len(self.condition_encoder.classes_)}")
        print(f"   ‚úì Medication classes: {len(self.medication_encoder.classes_)}")
        
        # Class weights ƒë·ªÉ x·ª≠ l√Ω imbalanced data
        condition_weights = compute_class_weight('balanced', classes=np.unique(y_condition), y=y_condition)
        medication_weights = compute_class_weight('balanced', classes=np.unique(y_medication), y=y_medication)
        
        self.condition_class_weights = dict(enumerate(condition_weights))
        self.medication_class_weights = dict(enumerate(medication_weights))
        
        return X, y_condition, y_medication
    
    def build_advanced_ensemble(self, model_name='model'):
        """X√¢y d·ª±ng ensemble model ti√™n ti·∫øn v·ªõi ML algorithms"""
        print(f"üèóÔ∏è X√¢y d·ª±ng {model_name} v·ªõi Ensemble Learning...")
        
        # 1. Random Forest v·ªõi hyperparameter tuning
        rf_model = RandomForestClassifier(
            n_estimators=200,
            max_depth=15,
            min_samples_split=5,
            min_samples_leaf=2,
            max_features='sqrt',
            random_state=42,
            n_jobs=-1
        )
        
        # 2. Gradient Boosting
        gb_model = GradientBoostingClassifier(
            n_estimators=150,
            max_depth=8,
            learning_rate=0.1,
            subsample=0.8,
            random_state=42
        )
        
        # 3. MLP Neural Network
        mlp_model = MLPClassifier(
            hidden_layer_sizes=(256, 128, 64, 32),
            activation='relu',
            solver='adam',
            alpha=0.001,
            learning_rate='adaptive',
            learning_rate_init=0.001,
            max_iter=500,
            random_state=42,
            early_stopping=True,
            validation_fraction=0.1,
            n_iter_no_change=20
        )
        
        # 4. Ensemble v·ªõi Voting
        ensemble_model = VotingClassifier(
            estimators=[
                ('rf', rf_model),
                ('gb', gb_model), 
                ('mlp', mlp_model)
            ],
            voting='soft'  # S·ª≠ d·ª•ng probability voting
        )
        
        print(f"   ‚úì Ensemble g·ªìm 3 models: RandomForest + GradientBoosting + MLP")
        return ensemble_model
    
    def train_advanced_models(self, X, y_condition, y_medication, use_cross_validation=True):
        """Training ensemble models v·ªõi k·ªπ thu·∫≠t ML ti√™n ti·∫øn"""
        print("üöÄ B·∫Øt ƒë·∫ßu training Ensemble Models v·ªõi Advanced ML...")
        
        # Chia d·ªØ li·ªáu v·ªõi stratified split ƒë·ªÉ ƒë·∫£m b·∫£o ph√¢n b·ªë ƒë·ªÅu
        sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)
        train_idx, test_idx = next(sss.split(X, y_condition))
        
        X_train, X_test = X[train_idx], X[test_idx]
        y_cond_train, y_cond_test = y_condition[train_idx], y_condition[test_idx]
        y_med_train, y_med_test = y_medication[train_idx], y_medication[test_idx]
        
        print(f"   üìä Training set: {len(X_train)} samples")
        print(f"   üìä Test set: {len(X_test)} samples")
        
        # === TRAINING CONDITION MODEL ===
        print("\nüè• Training Ensemble Model D·ª± ƒëo√°n T√¨nh tr·∫°ng B·ªánh...")
        self.condition_model = self.build_advanced_ensemble('Condition Ensemble')
        
        # Cross-validation tr∆∞·ªõc khi training
        if use_cross_validation and len(X_train) > 1000:
            print("   üîÑ Th·ª±c hi·ªán Cross-Validation...")
            cv_scores = cross_val_score(self.condition_model, X_train, y_cond_train, cv=3, scoring='accuracy', n_jobs=-1)
            print(f"   üìä CV Accuracy: {cv_scores.mean():.3f} (+/- {cv_scores.std() * 2:.3f})")
        
        # Training model
        print("   üöÄ Training...")
        self.condition_model.fit(X_train, y_cond_train)
        
        # === TRAINING MEDICATION MODEL ===
        print("\nüíä Training Ensemble Model ƒê·ªÅ xu·∫•t Thu·ªëc...")
        self.medication_model = self.build_advanced_ensemble('Medication Ensemble')
        
        # Cross-validation
        if use_cross_validation and len(X_train) > 1000:
            print("   üîÑ Th·ª±c hi·ªán Cross-Validation...")
            cv_scores = cross_val_score(self.medication_model, X_train, y_med_train, cv=3, scoring='accuracy', n_jobs=-1)
            print(f"   üìä CV Accuracy: {cv_scores.mean():.3f} (+/- {cv_scores.std() * 2:.3f})")
        
        # Training model
        print("   üöÄ Training...")
        self.medication_model.fit(X_train, y_med_train)
        
        # === ƒê√ÅNH GI√Å MODELS ===
        print("\nüìä ƒê√ÅNH GI√Å HI·ªÜU QU·∫¢ ENSEMBLE MODELS:")
        
        # Condition model evaluation
        cond_pred = self.condition_model.predict(X_test)
        cond_accuracy = accuracy_score(y_cond_test, cond_pred)
        
        # Medication model evaluation
        med_pred = self.medication_model.predict(X_test)
        med_accuracy = accuracy_score(y_med_test, med_pred)
        
        # Top-3 accuracy calculation
        cond_proba = self.condition_model.predict_proba(X_test)
        med_proba = self.medication_model.predict_proba(X_test)
        
        # Calculate top-3 accuracy manually
        cond_top3_acc = self._calculate_top_k_accuracy(y_cond_test, cond_proba, k=3)
        med_top3_acc = self._calculate_top_k_accuracy(y_med_test, med_proba, k=3)
        
        # Feature importance analysis
        self._analyze_feature_importance()
        
        self.model_metrics = {
            'condition_accuracy': cond_accuracy,
            'medication_accuracy': med_accuracy,
            'condition_top3_accuracy': cond_top3_acc,
            'medication_top3_accuracy': med_top3_acc,
            'training_samples': len(X_train),
            'test_samples': len(X_test)
        }
        
        print(f"üéØ ƒê·ªô ch√≠nh x√°c d·ª± ƒëo√°n t√¨nh tr·∫°ng b·ªánh: {cond_accuracy:.3f} ({cond_accuracy:.1%})")
        print(f"üéØ Top-3 accuracy t√¨nh tr·∫°ng b·ªánh: {cond_top3_acc:.3f} ({cond_top3_acc:.1%})")
        print(f"üíä ƒê·ªô ch√≠nh x√°c ƒë·ªÅ xu·∫•t thu·ªëc: {med_accuracy:.3f} ({med_accuracy:.1%})")
        print(f"üíä Top-3 accuracy thu·ªëc: {med_top3_acc:.3f} ({med_top3_acc:.1%})")
        
        return True, True
    
    def _calculate_top_k_accuracy(self, y_true, y_proba, k=3):
        """T√≠nh to√°n top-k accuracy"""
        top_k_pred = np.argsort(y_proba, axis=1)[:, -k:]
        correct = 0
        for i, true_label in enumerate(y_true):
            if true_label in top_k_pred[i]:
                correct += 1
        return correct / len(y_true)
    
    def _analyze_feature_importance(self):
        """Ph√¢n t√≠ch feature importance"""
        print("\nüîç PH√ÇN T√çCH FEATURE IMPORTANCE:")
        
        # L·∫•y feature importance t·ª´ Random Forest
        if hasattr(self.condition_model, 'named_estimators_'):
            rf_model = self.condition_model.named_estimators_['rf']
            feature_importance = rf_model.feature_importances_
            
            importance_dict = dict(zip(self.feature_columns, feature_importance))
            sorted_features = sorted(importance_dict.items(), key=lambda x: x[1], reverse=True)
            
            print("   üìä Top features cho d·ª± ƒëo√°n b·ªánh:")
            for feature, importance in sorted_features:
                print(f"      ‚Ä¢ {feature}: {importance:.3f}")
        else:
            print("   ‚ö†Ô∏è  Feature importance ch·ªâ kh·∫£ d·ª•ng cho ensemble models")
    
    def save_models(self, model_dir='models'):
        """L∆∞u models v√† metadata v·ªõi timestamp"""
        print("üíæ ƒêang l∆∞u models v√† metadata...")
        
        # T·∫°o th∆∞ m·ª•c models n·∫øu ch∆∞a c√≥
        if not os.path.exists(model_dir):
            os.makedirs(model_dir)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # L∆∞u models (pickle format)
        condition_path = os.path.join(model_dir, f'condition_model_{timestamp}.pkl')
        medication_path = os.path.join(model_dir, f'medication_model_{timestamp}.pkl')
        
        with open(condition_path, 'wb') as f:
            pickle.dump(self.condition_model, f)
        with open(medication_path, 'wb') as f:
            pickle.dump(self.medication_model, f)
        
        # L∆∞u encoders v√† metadata
        metadata = {
            'label_encoders': self.label_encoders,
            'scaler': self.scaler,
            'condition_encoder': self.condition_encoder,
            'medication_encoder': self.medication_encoder,
            'feature_columns': self.feature_columns,
            'model_metrics': self.model_metrics,
            'timestamp': timestamp,
            'condition_model_path': condition_path,
            'medication_model_path': medication_path
        }
        
        metadata_path = os.path.join(model_dir, f'metadata_{timestamp}.pkl')
        with open(metadata_path, 'wb') as f:
            pickle.dump(metadata, f)
        
        # L∆∞u phi√™n b·∫£n m·ªõi nh·∫•t
        with open(os.path.join(model_dir, 'latest_metadata.pkl'), 'wb') as f:
            pickle.dump(metadata, f)
        
        print(f"‚úÖ ƒê√£ l∆∞u models v√† metadata v√†o {model_dir}/")
        print(f"   ‚Ä¢ Condition model: {condition_path}")
        print(f"   ‚Ä¢ Medication model: {medication_path}")
        print(f"   ‚Ä¢ Metadata: {metadata_path}")
        
    def load_models(self, model_dir='models', use_latest=True):
        """T·∫£i models ƒë√£ l∆∞u"""
        try:
            metadata_path = os.path.join(model_dir, 'latest_metadata.pkl') if use_latest else None
            
            if not metadata_path or not os.path.exists(metadata_path):
                print("‚ùå Kh√¥ng t√¨m th·∫•y models ƒë√£ l∆∞u.")
                return False
            
            with open(metadata_path, 'rb') as f:
                metadata = pickle.load(f)
            
            # T·∫£i models (pickle format thay v√¨ h5)
            with open(metadata['condition_model_path'], 'rb') as f:
                self.condition_model = pickle.load(f)
            with open(metadata['medication_model_path'], 'rb') as f:
                self.medication_model = pickle.load(f)
            
            # T·∫£i encoders
            self.label_encoders = metadata['label_encoders']
            self.scaler = metadata['scaler']
            self.condition_encoder = metadata['condition_encoder']
            self.medication_encoder = metadata['medication_encoder']
            self.feature_columns = metadata['feature_columns']
            self.model_metrics = metadata.get('model_metrics', {})
            
            print(f"‚úÖ ƒê√£ t·∫£i ensemble models th√†nh c√¥ng! (Timestamp: {metadata['timestamp']})")
            if self.model_metrics:
                print(f"   üìä Condition accuracy: {self.model_metrics.get('condition_accuracy', 0):.1%}")
                print(f"   üìä Medication accuracy: {self.model_metrics.get('medication_accuracy', 0):.1%}")
            
            return True
            
        except Exception as e:
            print(f"‚ùå L·ªói t·∫£i models: {str(e)}")
            return False
    
    def predict_with_confidence(self, age, gender, blood_type, admission_type, test_results, top_k=3):
        """D·ª± ƒëo√°n v·ªõi confidence scores v√† top-k results"""
        if self.condition_model is None or self.medication_model is None:
            return "‚ùå Models ch∆∞a ƒë∆∞·ª£c training!"
        
        try:
            # Feature engineering cho input
            age_group = 'Child' if age < 18 else 'Young_Adult' if age < 35 else 'Adult' if age < 50 else 'Middle_Age' if age < 65 else 'Senior'
            
            # Risk score calculation
            risk_score = (age / 100) * 0.3
            risk_score += {'Normal': 0.1, 'Inconclusive': 0.5, 'Abnormal': 0.9}.get(test_results, 0.5) * 0.4
            risk_score += {'Elective': 0.2, 'Urgent': 0.6, 'Emergency': 1.0}.get(admission_type, 0.5) * 0.3
            
            # Chu·∫©n b·ªã input data
            input_data = {
                'Age': [age],
                'Gender': [gender],
                'Blood Type': [blood_type], 
                'Admission Type': [admission_type],
                'Test Results': [test_results],
                'Age_Group': [age_group],
                'Risk_Score': [risk_score]
            }
            
            df_input = pd.DataFrame(input_data)
            
            # Encode categorical features
            for col in ['Gender', 'Blood Type', 'Admission Type', 'Test Results', 'Age_Group']:
                if col in self.label_encoders:
                    try:
                        df_input[col] = self.label_encoders[col].transform(df_input[col])
                    except ValueError:
                        # N·∫øu gi√° tr·ªã m·ªõi kh√¥ng c√≥ trong training data
                        df_input[col] = 0
            
            # Scale numerical features
            numerical_cols = ['Age', 'Risk_Score']
            df_input[numerical_cols] = self.scaler.transform(df_input[numerical_cols])
            
            X_input = df_input[self.feature_columns].values
            
            # D·ª± ƒëo√°n v·ªõi probability
            condition_proba = self.condition_model.predict_proba(X_input)[0]
            medication_proba = self.medication_model.predict_proba(X_input)[0]
            
            # Top-k predictions
            condition_top_k = np.argsort(condition_proba)[-top_k:][::-1]
            medication_top_k = np.argsort(medication_proba)[-top_k:][::-1]
            
            # Chuy·ªÉn ƒë·ªïi v·ªÅ t√™n g·ªëc
            condition_predictions = []
            for idx in condition_top_k:
                condition_name = self.condition_encoder.inverse_transform([idx])[0]
                confidence = condition_proba[idx]
                condition_predictions.append({
                    'condition': condition_name,
                    'confidence': confidence
                })
            
            medication_predictions = []
            for idx in medication_top_k:
                medication_name = self.medication_encoder.inverse_transform([idx])[0]
                confidence = medication_proba[idx]
                medication_predictions.append({
                    'medication': medication_name,
                    'confidence': confidence
                })
            
            return {
                'condition_predictions': condition_predictions,
                'medication_predictions': medication_predictions,
                'risk_score': risk_score,
                'age_group': age_group,
                'input_processed': True
            }
            
        except Exception as e:
            return f"‚ùå L·ªói d·ª± ƒëo√°n: {str(e)}"
    
    def interactive_chat(self):
        """Interface chat chuy√™n nghi·ªáp v·ªõi nhi·ªÅu t√≠nh nƒÉng"""
        print("\n" + "="*60)
        print("üè• PROFESSIONAL HEALTHCARE AI CHATBOT")
        print("="*60)
        print("ü§ñ Ch√†o m·ª´ng ƒë·∫øn v·ªõi Healthcare AI Chatbot chuy√™n nghi·ªáp!")
        print("üéØ T√¥i c√≥ th·ªÉ d·ª± ƒëo√°n t√¨nh tr·∫°ng b·ªánh v√† ƒë·ªÅ xu·∫•t thu·ªëc v·ªõi ƒë·ªô ch√≠nh x√°c cao.")
        
        if self.model_metrics:
            print(f"üìä Hi·ªáu su·∫•t model: Condition {self.model_metrics.get('condition_accuracy', 0):.1%}, Medication {self.model_metrics.get('medication_accuracy', 0):.1%}")
        
        print("\nüìã L·ªánh c√≥ s·∫µn:")
        print("   ‚Ä¢ 'predict' - D·ª± ƒëo√°n cho b·ªánh nh√¢n m·ªõi")
        print("   ‚Ä¢ 'batch' - D·ª± ƒëo√°n h√†ng lo·∫°t")
        print("   ‚Ä¢ 'stats' - Xem th·ªëng k√™ model")
        print("   ‚Ä¢ 'help' - Xem h∆∞·ªõng d·∫´n")
        print("   ‚Ä¢ 'quit' - Tho√°t ch∆∞∆°ng tr√¨nh")
        print()
        
        while True:
            command = input("üí¨ Nh·∫≠p l·ªánh (predict/batch/stats/help/quit): ").lower().strip()
            
            if command == 'quit':
                print("\nüëã C·∫£m ∆°n b·∫°n ƒë√£ s·ª≠ d·ª•ng Healthcare AI Chatbot!")
                break
                
            elif command == 'predict':
                self._handle_single_prediction()
                
            elif command == 'batch':
                self._handle_batch_prediction()
                
            elif command == 'stats':
                self._show_model_stats()
                
            elif command == 'help':
                self._show_help()
                
            else:
                print("‚ùå L·ªánh kh√¥ng h·ª£p l·ªá. Nh·∫≠p 'help' ƒë·ªÉ xem h∆∞·ªõng d·∫´n.")
    
    def _handle_single_prediction(self):
        """X·ª≠ l√Ω d·ª± ƒëo√°n ƒë∆°n l·∫ª"""
        print("\nüìù NH·∫¨P TH√îNG TIN B·ªÜNH NH√ÇN:")
        print("-" * 40)
        
        try:
            age = int(input("üë§ Tu·ªïi (1-120): "))
            if not 1 <= age <= 120:
                print("‚ùå Tu·ªïi ph·∫£i t·ª´ 1-120!")
                return
            
            print("‚ö§  Gi·ªõi t√≠nh:")
            print("   1. Male")
            print("   2. Female")
            gender_choice = input("   Ch·ªçn (1-2): ")
            gender = "Male" if gender_choice == "1" else "Female"
            
            print("ü©∏ Nh√≥m m√°u:")
            blood_types = ["A+", "A-", "B+", "B-", "AB+", "AB-", "O+", "O-"]
            for i, bt in enumerate(blood_types, 1):
                print(f"   {i}. {bt}")
            bt_choice = int(input("   Ch·ªçn (1-8): ")) - 1
            blood_type = blood_types[bt_choice]
            
            print("üè• Lo·∫°i nh·∫≠p vi·ªán:")
            print("   1. Emergency")
            print("   2. Urgent") 
            print("   3. Elective")
            adm_choice = input("   Ch·ªçn (1-3): ")
            admission_types = ["Emergency", "Urgent", "Elective"]
            admission_type = admission_types[int(adm_choice) - 1]
            
            print("üìä K·∫øt qu·∫£ x√©t nghi·ªám:")
            print("   1. Normal")
            print("   2. Abnormal")
            print("   3. Inconclusive")
            test_choice = input("   Ch·ªçn (1-3): ")
            test_results_list = ["Normal", "Abnormal", "Inconclusive"]
            test_results = test_results_list[int(test_choice) - 1]
            
            # D·ª± ƒëo√°n
            print("\nü§î ƒêang ph√¢n t√≠ch...")
            result = self.predict_with_confidence(age, gender, blood_type, admission_type, test_results, top_k=3)
            
            if isinstance(result, dict):
                print("\nüîç K·∫æT QU·∫¢ D·ª∞ ƒêO√ÅN CHI TI·∫æT:")
                print("=" * 50)
                
                print(f"üë§ Th√¥ng tin: {age} tu·ªïi, {gender}, {blood_type}")
                print(f"üè• Nh·∫≠p vi·ªán: {admission_type}, XN: {test_results}")
                print(f"‚ö†Ô∏è  Risk Score: {result['risk_score']:.2f}")
                print(f"üë• Nh√≥m tu·ªïi: {result['age_group']}")
                
                print("\nüè• D·ª∞ ƒêO√ÅN T√åNH TR·∫†NG B·ªÜNH (Top 3):")
                for i, pred in enumerate(result['condition_predictions'], 1):
                    print(f"   {i}. {pred['condition']:<15} (Tin c·∫≠y: {pred['confidence']:.1%})")
                
                print("\nüíä ƒê·ªÄ XU·∫§T THU·ªêC (Top 3):")
                for i, pred in enumerate(result['medication_predictions'], 1):
                    print(f"   {i}. {pred['medication']:<15} (Tin c·∫≠y: {pred['confidence']:.1%})")
                
                print("\n‚ö†Ô∏è  L∆ØU √ù QUAN TR·ªåNG:")
                print("   ‚Ä¢ K·∫øt qu·∫£ ch·ªâ mang t√≠nh ch·∫•t tham kh·∫£o")
                print("   ‚Ä¢ Vui l√≤ng tham kh·∫£o √Ω ki·∫øn b√°c sƒ© chuy√™n khoa")
                print("   ‚Ä¢ Kh√¥ng t·ª± √Ω s·ª≠ d·ª•ng thu·ªëc khi ch∆∞a ƒë∆∞·ª£c ch·ªâ ƒë·ªãnh")
                
            else:
                print(f"‚ùå {result}")
                
        except (ValueError, IndexError):
            print("‚ùå D·ªØ li·ªáu nh·∫≠p kh√¥ng h·ª£p l·ªá!")
        except KeyboardInterrupt:
            print("\n‚èπÔ∏è  ƒê√£ h·ªßy thao t√°c.")
        except Exception as e:
            print(f"‚ùå L·ªói: {str(e)}")
    
    def _handle_batch_prediction(self):
        """X·ª≠ l√Ω d·ª± ƒëo√°n h√†ng lo·∫°t"""
        print("\nüìä D·ª∞ ƒêO√ÅN H√ÄNG LO·∫†T - 5 TR∆Ø·ªúNG H·ª¢P M·∫™U:")
        print("-" * 50)
        
        samples = [
            (45, "Male", "A+", "Emergency", "Abnormal", "Ng∆∞·ªùi ƒë√†n √¥ng trung ni√™n c·∫•p c·ª©u"),
            (67, "Female", "O-", "Urgent", "Abnormal", "Ph·ª• n·ªØ cao tu·ªïi nh·∫≠p vi·ªán kh·∫©n c·∫•p"),
            (25, "Male", "B+", "Elective", "Normal", "Thanh ni√™n kh√°m t·ªïng qu√°t"),
            (55, "Female", "AB+", "Urgent", "Inconclusive", "Ph·ª• n·ªØ trung ni√™n, KQ kh√¥ng r√µ r√†ng"),
            (8, "Male", "O+", "Emergency", "Abnormal", "Tr·∫ª em c·∫•p c·ª©u")
        ]
        
        for i, (age, gender, blood, admission, test, description) in enumerate(samples, 1):
            print(f"\nüî∏ TR∆Ø·ªúNG H·ª¢P {i}: {description}")
            print(f"   üìã Th√¥ng tin: {age} tu·ªïi, {gender}, {blood}, {admission}, {test}")
            
            result = self.predict_with_confidence(age, gender, blood, admission, test, top_k=2)
            
            if isinstance(result, dict):
                top_condition = result['condition_predictions'][0]
                top_medication = result['medication_predictions'][0]
                
                print(f"   üè• D·ª± ƒëo√°n: {top_condition['condition']} ({top_condition['confidence']:.1%})")
                print(f"   üíä Thu·ªëc: {top_medication['medication']} ({top_medication['confidence']:.1%})")
                print(f"   ‚ö†Ô∏è  Risk: {result['risk_score']:.2f}")
            else:
                print(f"   ‚ùå L·ªói: {result}")
    
    def _show_model_stats(self):
        """Hi·ªÉn th·ªã th·ªëng k√™ model"""
        if not self.model_metrics:
            print("‚ùå Ch∆∞a c√≥ th√¥ng tin th·ªëng k√™ model!")
            return
        
        print("\nüìà TH·ªêNG K√ä HI·ªÜU SU·∫§T MODEL:")
        print("=" * 40)
        print(f"üéØ ƒê·ªô ch√≠nh x√°c d·ª± ƒëo√°n b·ªánh: {self.model_metrics.get('condition_accuracy', 0):.3f} ({self.model_metrics.get('condition_accuracy', 0):.1%})")
        print(f"üéØ Top-3 accuracy b·ªánh: {self.model_metrics.get('condition_top3_accuracy', 0):.3f} ({self.model_metrics.get('condition_top3_accuracy', 0):.1%})")
        print(f"üíä ƒê·ªô ch√≠nh x√°c ƒë·ªÅ xu·∫•t thu·ªëc: {self.model_metrics.get('medication_accuracy', 0):.3f} ({self.model_metrics.get('medication_accuracy', 0):.1%})")
        print(f"üíä Top-3 accuracy thu·ªëc: {self.model_metrics.get('medication_top3_accuracy', 0):.3f} ({self.model_metrics.get('medication_top3_accuracy', 0):.1%})")
        print(f"üìä D·ªØ li·ªáu training: {self.model_metrics.get('training_samples', 0):,} samples")
        print(f"üìä D·ªØ li·ªáu test: {self.model_metrics.get('test_samples', 0):,} samples")
        
        if hasattr(self, 'condition_encoder'):
            print(f"üè• S·ªë lo·∫°i b·ªánh: {len(self.condition_encoder.classes_)}")
            print(f"üíä S·ªë lo·∫°i thu·ªëc: {len(self.medication_encoder.classes_)}")
    
    def _show_help(self):
        """Hi·ªÉn th·ªã h∆∞·ªõng d·∫´n s·ª≠ d·ª•ng"""
        print("\nüìñ H∆Ø·ªöNG D·∫™N S·ª¨ D·ª§NG:")
        print("=" * 40)
        print("üî∏ predict: D·ª± ƒëo√°n cho m·ªôt b·ªánh nh√¢n")
        print("   - Nh·∫≠p th√¥ng tin theo h∆∞·ªõng d·∫´n")
        print("   - Nh·∫≠n k·∫øt qu·∫£ top-3 v·ªõi confidence score")
        print()
        print("üî∏ batch: Xem v√≠ d·ª• d·ª± ƒëo√°n h√†ng lo·∫°t")
        print("   - 5 tr∆∞·ªùng h·ª£p m·∫´u ƒëa d·∫°ng")
        print("   - So s√°nh k·∫øt qu·∫£ d·ª± ƒëo√°n")
        print()
        print("üî∏ stats: Xem th·ªëng k√™ hi·ªáu su·∫•t model")
        print("   - ƒê·ªô ch√≠nh x√°c c·ªßa model")
        print("   - Th√¥ng tin v·ªÅ d·ªØ li·ªáu training")
        print()
        print("üî∏ help: Hi·ªÉn th·ªã h∆∞·ªõng d·∫´n n√†y")
        print("üî∏ quit: Tho√°t ch∆∞∆°ng tr√¨nh")
        print()
        print("‚ö†Ô∏è  L∆ØU √ù: K·∫øt qu·∫£ ch·ªâ mang t√≠nh tham kh·∫£o!")

def main():
    """H√†m main chuy√™n nghi·ªáp"""
    print("üöÄ KH·ªûI ƒê·ªòNG PROFESSIONAL HEALTHCARE AI CHATBOT")
    print("=" * 60)
    
    chatbot = ProfessionalHealthcareChatbot()
    
    # Ki·ªÉm tra models ƒë√£ c√≥ ch∆∞a
    if chatbot.load_models():
        print("‚úÖ ƒê√£ t·∫£i models th√†nh c√¥ng!")
    else:
        print("üîÑ Kh√¥ng t√¨m th·∫•y models. B·∫Øt ƒë·∫ßu training t·ª´ ƒë·∫ßu...")
        
        # H·ªèi ng∆∞·ªùi d√πng c√≥ mu·ªën d√πng to√†n b·ªô d·ªØ li·ªáu kh√¥ng
        print("\nüìä CH·ªåN CH·∫æ ƒê·ªò TRAINING:")
        print("1. üöÄ Full Training (to√†n b·ªô d·ªØ li·ªáu) - ƒê·ªô ch√≠nh x√°c cao nh·∫•t")
        print("2. ‚ö° Quick Training (5000 samples) - Nhanh h∆°n ƒë·ªÉ test")
        
        while True:
            choice = input("Ch·ªçn (1-2): ").strip()
            if choice in ['1', '2']:
                break
            print("‚ùå Vui l√≤ng ch·ªçn 1 ho·∫∑c 2!")
        
        use_full_data = (choice == '1')
        
        print(f"\nüéØ Ch·∫ø ƒë·ªô: {'Full Training' if use_full_data else 'Quick Training'}")
        print("ü§ñ S·ª≠ d·ª•ng Ensemble Learning: RandomForest + GradientBoosting + MLP")
        
        # T·∫£i v√† x·ª≠ l√Ω d·ªØ li·ªáu
        df = chatbot.load_and_preprocess_data('healthcare_dataset.csv', use_full_data=use_full_data)
        
        if df is None:
            print("‚ùå Kh√¥ng th·ªÉ t·∫£i d·ªØ li·ªáu. K·∫øt th√∫c ch∆∞∆°ng tr√¨nh.")
            return
        
        # Feature engineering
        df_enhanced = chatbot.feature_engineering(df)
        
        # Encode features
        df_encoded = chatbot.encode_features(df_enhanced)
        
        # Chu·∫©n b·ªã training data
        X, y_condition, y_medication = chatbot.prepare_training_data(df_encoded)
        
        # Training v·ªõi confirmation
        print(f"\n‚ö†Ô∏è  S·∫¥N S√ÄNG TRAINING V·ªöI {len(X):,} SAMPLES")
        print("üí° Qu√° tr√¨nh n√†y c√≥ th·ªÉ m·∫•t v√†i ph√∫t...")
        
        confirm = input("Ti·∫øp t·ª•c? (y/n): ").lower()
        if confirm != 'y':
            print("‚ùå ƒê√£ h·ªßy training.")
            return
        
        # B·∫Øt ƒë·∫ßu training
        print(f"\nüöÄ B·∫ÆT ƒê·∫¶U TRAINING...")
        start_time = datetime.now()
        
        try:
            chatbot.train_advanced_models(X, y_condition, y_medication)
            
            # L∆∞u models
            chatbot.save_models()
            
            end_time = datetime.now()
            training_time = end_time - start_time
            print(f"\n‚è±Ô∏è  Th·ªùi gian training: {training_time}")
            print("‚úÖ Training ho√†n th√†nh!")
            
        except KeyboardInterrupt:
            print("\n‚èπÔ∏è  Training ƒë√£ b·ªã d·ª´ng b·ªüi ng∆∞·ªùi d√πng.")
            return
        except Exception as e:
            print(f"\n‚ùå L·ªói training: {str(e)}")
            return
    
    # B·∫Øt ƒë·∫ßu chat interface
    print("\nüéâ CHATBOT S·∫¥N S√ÄNG PH·ª§C V·ª§!")
    chatbot.interactive_chat()

if __name__ == "__main__":
    main()
